{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "262806e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def forced_align_impl_jnp(logProbs, targets, blank, paths):\n",
    "    \"\"\"\n",
    "    This function performs forced alignment implementation using jax.numpy.\n",
    "    \n",
    "    Args:\n",
    "        logProbs (jnp.ndarray): The log probabilities.\n",
    "        targets (jnp.ndarray): The target values.\n",
    "        blank (int): The blank label.\n",
    "        paths (jnp.ndarray): The output paths.\n",
    "    \"\"\"\n",
    "    kNegInfinity = -jnp.inf\n",
    "    T = logProbs.shape[0]\n",
    "    L = targets.shape[0]\n",
    "    S = 2 * L + 1\n",
    "    alphas = jnp.full((2, S), kNegInfinity)\n",
    "    backPtr = jnp.full((T, S), -1, dtype=jnp.int8)\n",
    "    R = 0\n",
    "    for i in range(1, L):\n",
    "        if targets[i] == targets[i - 1]:\n",
    "            R += 1\n",
    "    if T < L + R:\n",
    "        raise ValueError(f\"targets length is too long for CTC. Found targets length: {T}, log_probs length: {L}, and number of repeats: {R}\")\n",
    "    start = 0 if T - (L + R) > 0 else 1\n",
    "    end = 1 if S == 1 else 2\n",
    "    for i in range(start, end):\n",
    "        labelIdx = blank if i % 2 == 0 else targets[i // 2]\n",
    "        alphas = alphas.at[0, i].set(logProbs[0, labelIdx])\n",
    "    for t in range(1, T):\n",
    "        if T - t <= L + R:\n",
    "            if start % 2 == 1 and targets[start // 2] != targets[start // 2 + 1]:\n",
    "                start += 1\n",
    "            start += 1\n",
    "        if t <= L + R:\n",
    "            if end % 2 == 0 and end < 2 * L and targets[end // 2 - 1] != targets[end // 2]:\n",
    "                end += 1\n",
    "            end += 1\n",
    "        startloop = start\n",
    "        curIdxOffset = t % 2\n",
    "        prevIdxOffset = (t - 1) % 2\n",
    "        alphas = alphas.at[curIdxOffset, :].set(kNegInfinity)\n",
    "        if start == 0:\n",
    "            alphas = alphas.at[curIdxOffset, 0].set(alphas[prevIdxOffset, 0] + logProbs[t, blank])\n",
    "            backPtr = backPtr.at[t, 0].set(0)\n",
    "            startloop += 1\n",
    "        for i in range(startloop, end):\n",
    "            x0 = alphas[prevIdxOffset, i]\n",
    "            x1 = alphas[prevIdxOffset, i - 1]\n",
    "            x2 = kNegInfinity\n",
    "            labelIdx = blank if i % 2 == 0 else targets[i // 2]\n",
    "            if i % 2 != 0 and i != 1 and targets[i // 2] != targets[i // 2 - 1]:\n",
    "                x2 = alphas[prevIdxOffset, i - 2]\n",
    "            result = 0.0\n",
    "            if x2 > x1 and x2 > x0:\n",
    "                result = x2\n",
    "                backPtr = backPtr.at[t, i].set(2)\n",
    "            elif x1 > x0 and x1 > x2:\n",
    "                result = x1\n",
    "                backPtr = backPtr.at[t, i].set(1)\n",
    "            else:\n",
    "                result = x0\n",
    "                backPtr = backPtr.at[t, i].set(0)\n",
    "            alphas = alphas.at[curIdxOffset, i].set(result + logProbs[t, labelIdx])\n",
    "    idx1 = (T - 1) % 2\n",
    "    ltrIdx = S - 1 if alphas[idx1, S - 1] > alphas[idx1, S - 2] else S - 2\n",
    "    for t in range(T - 1, -1, -1):\n",
    "        lbl_idx = blank if ltrIdx % 2 == 0 else targets[ltrIdx // 2]\n",
    "        paths = paths.at[t].set(lbl_idx)\n",
    "        ltrIdx -= backPtr[t, ltrIdx]\n",
    "    return paths, alphas, backPtr\n",
    "\n",
    "def compute_jnp(logProbs, targets, inputLengths, targetLengths, blank):\n",
    "    \"\"\"\n",
    "    This function performs computation using jax.numpy.\n",
    "    \n",
    "    Args:\n",
    "        logProbs (jnp.ndarray): The log probabilities.\n",
    "        targets (jnp.ndarray): The target values.\n",
    "        inputLengths (int): The input lengths.\n",
    "        targetLengths (int): The target lengths.\n",
    "        blank (int): The blank label.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: The output paths and the log probabilities for those paths.\n",
    "    \"\"\"\n",
    "    if not isinstance(logProbs, jnp.ndarray):\n",
    "        raise ValueError(\"log_probs must be a jax numpy array\")\n",
    "    if not isinstance(targets, jnp.ndarray):\n",
    "        raise ValueError(\"targets must be a jax numpy array\")\n",
    "    if not jnp.issubdtype(logProbs.dtype, jnp.floating):\n",
    "        raise ValueError(\"log_probs must be float64, float32 or float16 (half) type\")\n",
    "    if not jnp.issubdtype(targets.dtype, jnp.integer):\n",
    "        raise ValueError(\"targets must be int32 or int64 type\")\n",
    "    if len(logProbs.shape) != 2:\n",
    "        raise ValueError(\"log_probs must be 2-D (input length, num classes)\")\n",
    "    if len(targets.shape) != 1:\n",
    "        raise ValueError(\"targets must be 1-D (target length,)\")\n",
    "    if jnp.ndim(inputLengths) != 0:\n",
    "        raise ValueError(\"input_lengths must be 0-D\")\n",
    "    if jnp.ndim(targetLengths) != 0:\n",
    "        raise ValueError(\"target_lengths must be 0-D\")\n",
    "    if blank < 0 or blank >= logProbs.shape[-1]:\n",
    "        raise ValueError(\"blank must be within [0, num classes)\")\n",
    "    if logProbs.shape[0] != inputLengths:\n",
    "        raise ValueError(\"input length mismatch\")\n",
    "    if targets.shape[0] != targetLengths:\n",
    "        raise ValueError(\"target length mismatch\")\n",
    "    T = logProbs.shape[0]\n",
    "    paths = jnp.zeros(T, dtype=targets.dtype)\n",
    "    paths, alphas, backPtr = forced_align_impl_jnp(logProbs, targets, blank, paths)\n",
    "    return paths, logProbs[jnp.arange(T), paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f4d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test this with some random data\n",
    "logProbs = jnp.array([[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8], [0.9, 1.0, 1.1, 1.2]])\n",
    "targets = jnp.array([0, 2, 3])\n",
    "blank = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28856c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "logProbs = jax.nn.log_softmax(logProbs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "418ec94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lengths = jnp.array(logProbs.shape[0])\n",
    "target_lengths = jnp.array(targets.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6df5dff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([0, 2, 3], dtype=int32),\n",
       " Array([-1.5425494, -1.3425493, -1.2425493], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_jnp(logProbs, targets, input_lengths, target_lengths, blank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ead04",
   "metadata": {},
   "source": [
    "## Numpy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e22e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def forced_align_impl_np(logProbs, targets, blank, paths):\n",
    "    kNegInfinity = -np.inf\n",
    "    T = logProbs.shape[0]\n",
    "    L = targets.shape[0]\n",
    "    S = 2 * L + 1\n",
    "    alphas = np.full((2, S), kNegInfinity)\n",
    "    backPtr = np.full((T, S), -1, dtype=np.int8)\n",
    "    R = 0\n",
    "    for i in range(1, L):\n",
    "        if targets[i] == targets[i - 1]:\n",
    "            R += 1\n",
    "    if T < L + R:\n",
    "        raise ValueError(f\"targets length is too long for CTC. Found targets length: {T}, log_probs length: {L}, and number of repeats: {R}\")\n",
    "    start = 0 if T - (L + R) > 0 else 1\n",
    "    end = 1 if S == 1 else 2\n",
    "    for i in range(start, end):\n",
    "        labelIdx = blank if i % 2 == 0 else targets[i // 2]\n",
    "        alphas[0, i] = logProbs[0, labelIdx]\n",
    "    for t in range(1, T):\n",
    "        if T - t <= L + R:\n",
    "            if start % 2 == 1 and targets[start // 2] != targets[start // 2 + 1]:\n",
    "                start += 1\n",
    "            start += 1\n",
    "        if t <= L + R:\n",
    "            if end % 2 == 0 and end < 2 * L and targets[end // 2 - 1] != targets[end // 2]:\n",
    "                end += 1\n",
    "            end += 1\n",
    "        startloop = start\n",
    "        curIdxOffset = t % 2\n",
    "        prevIdxOffset = (t - 1) % 2\n",
    "        alphas[curIdxOffset, :] = kNegInfinity\n",
    "        if start == 0:\n",
    "            alphas[curIdxOffset, 0] = alphas[prevIdxOffset, 0] + logProbs[t, blank]\n",
    "            backPtr[t, 0] = 0\n",
    "            startloop += 1\n",
    "        for i in range(startloop, end):\n",
    "            x0 = alphas[prevIdxOffset, i]\n",
    "            x1 = alphas[prevIdxOffset, i - 1]\n",
    "            x2 = kNegInfinity\n",
    "            labelIdx = blank if i % 2 == 0 else targets[i // 2]\n",
    "            if i % 2 != 0 and i != 1 and targets[i // 2] != targets[i // 2 - 1]:\n",
    "                x2 = alphas[prevIdxOffset, i - 2]\n",
    "            result = 0.0\n",
    "            if x2 > x1 and x2 > x0:\n",
    "                result = x2\n",
    "                backPtr[t, i] = 2\n",
    "            elif x1 > x0 and x1 > x2:\n",
    "                result = x1\n",
    "                backPtr[t, i] = 1\n",
    "            else:\n",
    "                result = x0\n",
    "                backPtr[t, i] = 0\n",
    "            alphas[curIdxOffset, i] = result + logProbs[t, labelIdx]\n",
    "    idx1 = (T - 1) % 2\n",
    "    ltrIdx = S - 1 if alphas[idx1, S - 1] > alphas[idx1, S - 2] else S - 2\n",
    "    for t in range(T - 1, -1, -1):\n",
    "        lbl_idx = blank if ltrIdx % 2 == 0 else targets[ltrIdx // 2]\n",
    "        paths[t] = lbl_idx\n",
    "        ltrIdx -= backPtr[t, ltrIdx]\n",
    "\n",
    "def compute_np(logProbs, targets, inputLengths, targetLengths, blank):\n",
    "    if not isinstance(logProbs, np.ndarray):\n",
    "        raise ValueError(\"log_probs must be a numpy array\")\n",
    "    if not isinstance(targets, np.ndarray):\n",
    "        raise ValueError(\"targets must be a numpy array\")\n",
    "    if not np.issubdtype(logProbs.dtype, np.floating):\n",
    "        raise ValueError(\"log_probs must be float64, float32 or float16 (half) type\")\n",
    "    if not np.issubdtype(targets.dtype, np.integer):\n",
    "        raise ValueError(\"targets must be int32 or int64 type\")\n",
    "    if len(logProbs.shape) != 2:\n",
    "        raise ValueError(\"log_probs must be 2-D (input length, num classes)\")\n",
    "    if len(targets.shape) != 1:\n",
    "        raise ValueError(\"targets must be 1-D (target length,)\")\n",
    "    if np.ndim(inputLengths) != 0:\n",
    "        raise ValueError(\"input_lengths must be 0-D\")\n",
    "    if np.ndim(targetLengths) != 0:\n",
    "        raise ValueError(\"target_lengths must be 0-D\")\n",
    "    if blank < 0 or blank >= logProbs.shape[-1]:\n",
    "        raise ValueError(\"blank must be within [0, num classes)\")\n",
    "    if logProbs.shape[0] != inputLengths:\n",
    "        raise ValueError(\"input length mismatch\")\n",
    "    if targets.shape[0] != targetLengths:\n",
    "        raise ValueError(\"target length mismatch\")\n",
    "    T = logProbs.shape[0]\n",
    "    paths = np.zeros(T, dtype=targets.dtype)\n",
    "    forced_align_impl_np(logProbs, targets, blank, paths)\n",
    "    return paths, logProbs[np.arange(T), paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8512e650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2, 3], dtype=int32),\n",
       " array([-1.5425494, -1.3425493, -1.2425493], dtype=float32))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_np(np.asarray(logProbs), np.asarray(targets), np.asarray(input_lengths), np.asarray(target_lengths), blank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b67b154",
   "metadata": {},
   "source": [
    "## Torch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b962026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.functional import forced_align\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62408460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1245398/3542591692.py:1: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  forced_align(torch.from_numpy(np.asarray(logProbs)), torch.from_numpy(np.asarray(targets)), torch.from_numpy(np.asarray(input_lengths)), torch.from_numpy(np.asarray(target_lengths)), blank)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 2, 3], dtype=torch.int32), tensor([-1.5425, -1.3425, -1.2425]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forced_align(torch.from_numpy(np.asarray(logProbs)), torch.from_numpy(np.asarray(targets)), torch.from_numpy(np.asarray(input_lengths)), torch.from_numpy(np.asarray(target_lengths)), blank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e432cd",
   "metadata": {},
   "source": [
    "## Parellized jax implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4f0c2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def inner_loop_fn(t, i, startloop, end, prevIdxOffset, curIdxOffset, alphas, backPtr, logProbs, targets, kNegInfinity, blank):\n",
    "    \"\"\"\n",
    "    This function represents the logic inside the inner loop of the forced_align_impl_jnp function.\n",
    "    \n",
    "    Args:\n",
    "        t (int): The outer loop variable.\n",
    "        i (int): The inner loop variable.\n",
    "        startloop (int): The starting index of the inner loop.\n",
    "        end (int): The ending index of the inner loop.\n",
    "        prevIdxOffset (int): The offset index of the previous timestep.\n",
    "        curIdxOffset (int): The offset index of the current timestep.\n",
    "        alphas (jnp.ndarray): The alpha values.\n",
    "        backPtr (jnp.ndarray): The backpointer values.\n",
    "        logProbs (jnp.ndarray): The log probabilities.\n",
    "        targets (jnp.ndarray): The target values.\n",
    "        kNegInfinity (float): A constant representing negative infinity.\n",
    "        blank (int): The blank label.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[jnp.ndarray, jnp.ndarray]: The updated alpha values and backpointer values.\n",
    "    \"\"\"\n",
    "    x0 = alphas[prevIdxOffset, i]\n",
    "    x1 = alphas[prevIdxOffset, i - 1]\n",
    "    x2 = kNegInfinity\n",
    "    labelIdx = jnp.where(i % 2 == 0, blank, targets[i // 2])\n",
    "    condition = jnp.logical_and(jnp.logical_and(i % 2 != 0, i != 1), targets[i // 2] != targets[i // 2 - 1])\n",
    "    x2 = jnp.where(condition, alphas[prevIdxOffset, i - 2], kNegInfinity)\n",
    "    result = 0.0\n",
    "    \n",
    "    cond1 = jnp.logical_and(x2 > x1, x2 > x0)\n",
    "    cond2 = jnp.logical_and(~cond1, jnp.logical_and(x1 > x0, x1 > x2))\n",
    "\n",
    "    result = jnp.where(cond1, x2, jnp.where(cond2, x1, x0))\n",
    "    backPtr_val = jnp.where(cond1, 2, jnp.where(cond2, 1, 0))\n",
    "    \n",
    "    return jnp.array([curIdxOffset, i, result + logProbs[t, labelIdx]]), jnp.array([t, i, backPtr_val])\n",
    "\n",
    "inner_loop_vmap = jax.vmap(inner_loop_fn, in_axes=(None, 0, None, None, None, None, None, None, None, None, None, None), out_axes=(0, 0))\n",
    "\n",
    "\n",
    "def forced_align_impl_jnp(logProbs, targets, blank, paths):\n",
    "    \"\"\"\n",
    "    This function performs forced alignment implementation using jax.numpy.\n",
    "    \n",
    "    Args:\n",
    "        logProbs (jnp.ndarray): The log probabilities.\n",
    "        targets (jnp.ndarray): The target values.\n",
    "        blank (int): The blank label.\n",
    "        paths (jnp.ndarray): The output paths.\n",
    "    \"\"\"\n",
    "    kNegInfinity = -jnp.inf\n",
    "    T = logProbs.shape[0]\n",
    "    L = targets.shape[0]\n",
    "    S = 2 * L + 1\n",
    "    alphas = jnp.full((2, S), kNegInfinity)\n",
    "    backPtr = jnp.full((T, S), -1, dtype=jnp.int8)\n",
    "    R = 0\n",
    "    for i in range(1, L):\n",
    "        if targets[i] == targets[i - 1]:\n",
    "            R += 1\n",
    "    if T < L + R:\n",
    "        raise ValueError(f\"targets length is too long for CTC. Found targets length: {T}, log_probs length: {L}, and number of repeats: {R}\")\n",
    "    start = 0 if T - (L + R) > 0 else 1\n",
    "    end = 1 if S == 1 else 2\n",
    "    for i in range(start, end):\n",
    "        labelIdx = blank if i % 2 == 0 else targets[i // 2]\n",
    "        alphas = alphas.at[0, i].set(logProbs[0, labelIdx])\n",
    "    for t in range(1, T):\n",
    "        if T - t <= L + R:\n",
    "            if start % 2 == 1 and targets[start // 2] != targets[start // 2 + 1]:\n",
    "                start += 1\n",
    "            start += 1\n",
    "        if t <= L + R:\n",
    "            if end % 2 == 0 and end < 2 * L and targets[end // 2 - 1] != targets[end // 2]:\n",
    "                end += 1\n",
    "            end += 1\n",
    "        startloop = start\n",
    "        curIdxOffset = t % 2\n",
    "        prevIdxOffset = (t - 1) % 2\n",
    "        alphas = alphas.at[curIdxOffset, :].set(kNegInfinity)\n",
    "        if start == 0:\n",
    "            alphas = alphas.at[curIdxOffset, 0].set(alphas[prevIdxOffset, 0] + logProbs[t, blank])\n",
    "            backPtr = backPtr.at[t, 0].set(0)\n",
    "            startloop += 1\n",
    "        alphas_update, backPtr_update = inner_loop_vmap(t, jnp.arange(startloop, end), startloop, end, prevIdxOffset, curIdxOffset, alphas, backPtr, logProbs, targets, kNegInfinity, blank)\n",
    "        for i in range(alphas_update.shape[0]):\n",
    "            t, i, backPtr_val = backPtr_update[i]\n",
    "            curIdxOffset, i, updated_alpha = alphas_update[i]\n",
    "            backPtr = backPtr.at[int(t), int(i)].set(int(backPtr_val))\n",
    "            alphas = alphas.at[int(curIdxOffset), int(i)].set(updated_alpha)\n",
    "\n",
    "    idx1 = (T - 1) % 2\n",
    "    ltrIdx = jnp.where(alphas[idx1, S - 1] > alphas[idx1, S - 2], S - 1, S - 2)\n",
    "    for t in range(T - 1, -1, -1):\n",
    "        lbl_idx = jnp.where(ltrIdx % 2 == 0, blank, targets[ltrIdx // 2])\n",
    "        paths = paths.at[t].set(jnp.array(lbl_idx))\n",
    "        ltrIdx -= backPtr[t, ltrIdx]\n",
    "    return paths, alphas, backPtr\n",
    "\n",
    "def compute_jnp(logProbs, targets, inputLengths, targetLengths, blank):\n",
    "    \"\"\"\n",
    "    This function performs computation using jax.numpy.\n",
    "    \n",
    "    Args:\n",
    "        logProbs (jnp.ndarray): The log probabilities.\n",
    "        targets (jnp.ndarray): The target values.\n",
    "        inputLengths (int): The input lengths.\n",
    "        targetLengths (int): The target lengths.\n",
    "        blank (int): The blank label.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: The output paths and the log probabilities for those paths.\n",
    "    \"\"\"\n",
    "    if not isinstance(logProbs, jnp.ndarray):\n",
    "        raise ValueError(\"log_probs must be a jax numpy array\")\n",
    "    if not isinstance(targets, jnp.ndarray):\n",
    "        raise ValueError(\"targets must be a jax numpy array\")\n",
    "    if not jnp.issubdtype(logProbs.dtype, jnp.floating):\n",
    "        raise ValueError(\"log_probs must be float64, float32 or float16 (half) type\")\n",
    "    if not jnp.issubdtype(targets.dtype, jnp.integer):\n",
    "        raise ValueError(\"targets must be int32 or int64 type\")\n",
    "    if len(logProbs.shape) != 2:\n",
    "        raise ValueError(\"log_probs must be 2-D (input length, num classes)\")\n",
    "    if len(targets.shape) != 1:\n",
    "        raise ValueError(\"targets must be 1-D (target length,)\")\n",
    "    if jnp.ndim(inputLengths) != 0:\n",
    "        raise ValueError(\"input_lengths must be 0-D\")\n",
    "    if jnp.ndim(targetLengths) != 0:\n",
    "        raise ValueError(\"target_lengths must be 0-D\")\n",
    "    if blank < 0 or blank >= logProbs.shape[-1]:\n",
    "        raise ValueError(\"blank must be within [0, num classes)\")\n",
    "    if logProbs.shape[0] != inputLengths:\n",
    "        raise ValueError(\"input length mismatch\")\n",
    "    if targets.shape[0] != targetLengths:\n",
    "        raise ValueError(\"target length mismatch\")\n",
    "    T = logProbs.shape[0]\n",
    "    paths = jnp.zeros(T, dtype=targets.dtype)\n",
    "    paths, alphas, backPtr = forced_align_impl_jnp(logProbs, targets, blank, paths)\n",
    "    return paths, logProbs[jnp.arange(T), paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "750646f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape of backPtr: (3, 7)\n",
      "Input Shape of alphas: (2, 7)\n",
      "Input Shape of backPtr: (3, 7)\n",
      "Input Shape of alphas: (2, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Array([0, 2, 3], dtype=int32),\n",
       " Array([-1.5425494, -1.3425493, -1.2425493], dtype=float32))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test this with some random data\n",
    "logProbs = jnp.array([[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8], [0.9, 1.0, 1.1, 1.2]])\n",
    "targets = jnp.array([0, 2, 3])\n",
    "blank = 1\n",
    "\n",
    "logProbs = jax.nn.log_softmax(logProbs, axis=-1)\n",
    "\n",
    "input_lengths = jnp.array(logProbs.shape[0])\n",
    "target_lengths = jnp.array(targets.shape[0])\n",
    "\n",
    "compute_jnp(logProbs, targets, input_lengths, target_lengths, blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28da8d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "38bf247b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['targets.pt',\n",
       " 'target_lengths.pt',\n",
       " 'paths.pt',\n",
       " 'input_lengths.pt',\n",
       " 'emissions.pt']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Unzip the provided file\n",
    "with zipfile.ZipFile(\"forced_align_input_outputs.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"forced_align_input_outputs\")\n",
    "\n",
    "# Check the contents of the directory\n",
    "os.listdir(\"forced_align_input_outputs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4f2723bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-7.3520811e-03, -2.7093369e+01, -2.7509064e+01, ...,\n",
       "         -8.7403002e+00, -1.1601903e+01, -1.1159496e+01],\n",
       "        [-1.3696853e-02, -2.7963503e+01, -2.8412813e+01, ...,\n",
       "         -9.0036783e+00, -1.1766139e+01, -1.0991915e+01],\n",
       "        [-3.1517904e-02, -2.9013901e+01, -2.9537155e+01, ...,\n",
       "         -9.1752405e+00, -1.2215663e+01, -1.1296188e+01],\n",
       "        ...,\n",
       "        [-8.4026694e-02, -2.5163204e+01, -2.5194981e+01, ...,\n",
       "         -7.7668262e+00, -8.7488461e+00, -8.5354090e+00],\n",
       "        [-8.3044618e-02, -2.5117912e+01, -2.5149914e+01, ...,\n",
       "         -7.6841059e+00, -8.7871141e+00, -8.6122017e+00],\n",
       "        [-9.2383891e-02, -2.5157015e+01, -2.5237972e+01, ...,\n",
       "         -7.7255855e+00, -8.7317905e+00, -8.4821301e+00]], dtype=float32),\n",
       " array([12,  4,  4, ..., 19,  4,  4], dtype=int32),\n",
       " array(10658),\n",
       " array(1648),\n",
       " array([0, 0, 0, ..., 0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the provided tensors\n",
    "logProbs = torch.load(\"forced_align_input_outputs/emissions.pt\")\n",
    "targets = torch.load(\"forced_align_input_outputs/targets.pt\")\n",
    "inputLengths = torch.load(\"forced_align_input_outputs/input_lengths.pt\")\n",
    "targetLengths = torch.load(\"forced_align_input_outputs/target_lengths.pt\")\n",
    "paths = torch.load(\"forced_align_input_outputs/paths.pt\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "logProbs_np = logProbs.numpy()\n",
    "targets_np = targets.numpy()\n",
    "inputLengths_np = inputLengths.numpy()\n",
    "targetLengths_np = targetLengths.numpy()\n",
    "paths_np = paths.numpy()\n",
    "\n",
    "blank = 0\n",
    "\n",
    "logProbs_np, targets_np, inputLengths_np, targetLengths_np, paths_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d43ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_result, _ = compute_jnp(jnp.asarray(logProbs_np), jnp.asarray(targets_np), jnp.asarray(inputLengths_np), jnp.asarray(targetLengths_np), blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9128df16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  4,  0,  0,  0,  0,  0, 13,  0,  0,  5,  0,\n",
       "         0,  5,  0,  0,  7,  0,  0,  0,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0, 16,  0,  0,  0,  0,  0,  0,  0,  0, 16,  0,  0,  4,  0,  0,\n",
       "         9,  0,  0, 15,  0,  0,  0,  4,  0,  0,  4,  0,  0,  0,  0, 21,  0,  0,\n",
       "         0,  0,  4,  0,  0,  0,  0,  4,  0,  0, 12,  0,  0,  0,  0,  0, 14,  0,\n",
       "         0,  4,  0,  0,  0,  0,  0,  0,  0,  0], dtype=torch.int32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[415:515]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624eba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
