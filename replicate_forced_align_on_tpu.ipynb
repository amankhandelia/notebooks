{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3400cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def forced_align_impl_jnp(logProbs, targets, blank, paths):\n",
    "    \"\"\"\n",
    "    This function performs forced alignment implementation using jax.numpy.\n",
    "    \n",
    "    Args:\n",
    "        logProbs (jnp.ndarray): The log probabilities.\n",
    "        targets (jnp.ndarray): The target values.\n",
    "        blank (int): The blank label.\n",
    "        paths (jnp.ndarray): The output paths.\n",
    "    \"\"\"\n",
    "    kNegInfinity = -jnp.inf\n",
    "    T = logProbs.shape[0]\n",
    "    L = targets.shape[0]\n",
    "    S = 2 * L + 1\n",
    "    alphas = jnp.full((2, S), kNegInfinity)\n",
    "    backPtr = jnp.full((T, S), -1, dtype=jnp.int8)\n",
    "    R = 0\n",
    "    for i in range(1, L):\n",
    "        if targets[i] == targets[i - 1]:\n",
    "            R += 1\n",
    "    if T < L + R:\n",
    "        raise ValueError(f\"targets length is too long for CTC. Found targets length: {T}, log_probs length: {L}, and number of repeats: {R}\")\n",
    "    start = 0 if T - (L + R) > 0 else 1\n",
    "    end = 1 if S == 1 else 2\n",
    "    for i in range(start, end):\n",
    "        labelIdx = blank if i % 2 == 0 else targets[i // 2]\n",
    "        alphas = alphas.at[0, i].set(logProbs[0, labelIdx])\n",
    "    for t in range(1, T):\n",
    "        if T - t <= L + R:\n",
    "            if start % 2 == 1 and targets[start // 2] != targets[start // 2 + 1]:\n",
    "                start += 1\n",
    "            start += 1\n",
    "        if t <= L + R:\n",
    "            if end % 2 == 0 and end < 2 * L and targets[end // 2 - 1] != targets[end // 2]:\n",
    "                end += 1\n",
    "            end += 1\n",
    "        startloop = start\n",
    "        curIdxOffset = t % 2\n",
    "        prevIdxOffset = (t - 1) % 2\n",
    "        alphas = alphas.at[curIdxOffset, :].set(kNegInfinity)\n",
    "        if start == 0:\n",
    "            alphas = alphas.at[curIdxOffset, 0].set(alphas[prevIdxOffset, 0] + logProbs[t, blank])\n",
    "            backPtr = backPtr.at[t, 0].set(0)\n",
    "            startloop += 1\n",
    "        for i in range(startloop, end):\n",
    "            x0 = alphas[prevIdxOffset, i]\n",
    "            x1 = alphas[prevIdxOffset, i - 1]\n",
    "            x2 = kNegInfinity\n",
    "            labelIdx = blank if i % 2 == 0 else targets[i // 2]\n",
    "            if i % 2 != 0 and i != 1 and targets[i // 2] != targets[i // 2 - 1]:\n",
    "                x2 = alphas[prevIdxOffset, i - 2]\n",
    "            result = 0.0\n",
    "            if x2 > x1 and x2 > x0:\n",
    "                result = x2\n",
    "                backPtr = backPtr.at[t, i].set(2)\n",
    "            elif x1 > x0 and x1 > x2:\n",
    "                result = x1\n",
    "                backPtr = backPtr.at[t, i].set(1)\n",
    "            else:\n",
    "                result = x0\n",
    "                backPtr = backPtr.at[t, i].set(0)\n",
    "            alphas = alphas.at[curIdxOffset, i].set(result + logProbs[t, labelIdx])\n",
    "    idx1 = (T - 1) % 2\n",
    "    ltrIdx = S - 1 if alphas[idx1, S - 1] > alphas[idx1, S - 2] else S - 2\n",
    "    for t in range(T - 1, -1, -1):\n",
    "        lbl_idx = blank if ltrIdx % 2 == 0 else targets[ltrIdx // 2]\n",
    "        paths = paths.at[t].set(lbl_idx)\n",
    "        ltrIdx -= backPtr[t, ltrIdx]\n",
    "    return paths, alphas, backPtr\n",
    "\n",
    "def compute_jnp(logProbs, targets, inputLengths, targetLengths, blank):\n",
    "    \"\"\"\n",
    "    This function performs computation using jax.numpy.\n",
    "    \n",
    "    Args:\n",
    "        logProbs (jnp.ndarray): The log probabilities.\n",
    "        targets (jnp.ndarray): The target values.\n",
    "        inputLengths (int): The input lengths.\n",
    "        targetLengths (int): The target lengths.\n",
    "        blank (int): The blank label.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: The output paths and the log probabilities for those paths.\n",
    "    \"\"\"\n",
    "    if not isinstance(logProbs, jnp.ndarray):\n",
    "        raise ValueError(\"log_probs must be a jax numpy array\")\n",
    "    if not isinstance(targets, jnp.ndarray):\n",
    "        raise ValueError(\"targets must be a jax numpy array\")\n",
    "    if not jnp.issubdtype(logProbs.dtype, jnp.floating):\n",
    "        raise ValueError(\"log_probs must be float64, float32 or float16 (half) type\")\n",
    "    if not jnp.issubdtype(targets.dtype, jnp.integer):\n",
    "        raise ValueError(\"targets must be int32 or int64 type\")\n",
    "    if len(logProbs.shape) != 2:\n",
    "        raise ValueError(\"log_probs must be 2-D (input length, num classes)\")\n",
    "    if len(targets.shape) != 1:\n",
    "        raise ValueError(\"targets must be 1-D (target length,)\")\n",
    "    if jnp.ndim(inputLengths) != 0:\n",
    "        raise ValueError(\"input_lengths must be 0-D\")\n",
    "    if jnp.ndim(targetLengths) != 0:\n",
    "        raise ValueError(\"target_lengths must be 0-D\")\n",
    "    if blank < 0 or blank >= logProbs.shape[-1]:\n",
    "        raise ValueError(\"blank must be within [0, num classes)\")\n",
    "    if logProbs.shape[0] != inputLengths:\n",
    "        raise ValueError(\"input length mismatch\")\n",
    "    if targets.shape[0] != targetLengths:\n",
    "        raise ValueError(\"target length mismatch\")\n",
    "    T = logProbs.shape[0]\n",
    "    paths = jnp.zeros(T, dtype=targets.dtype)\n",
    "    paths, alphas, backPtr = forced_align_impl_jnp(logProbs, targets, blank, paths)\n",
    "    return paths, logProbs[jnp.arange(T), paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c8bd63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test this with some random data\n",
    "logProbs = jnp.array([[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8], [0.9, 1.0, 1.1, 1.2]])\n",
    "targets = jnp.array([0, 2, 3])\n",
    "blank = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7703f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "logProbs = jax.nn.log_softmax(logProbs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a63997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lengths = jnp.array(logProbs.shape[0])\n",
    "target_lengths = jnp.array(targets.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8e3830d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([0, 2, 3], dtype=int32),\n",
       " Array([-1.5425494, -1.3425493, -1.2425493], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_jnp(logProbs, targets, input_lengths, target_lengths, blank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5271e0f",
   "metadata": {},
   "source": [
    "## Numpy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50f215d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def forced_align_impl_np(logProbs, targets, blank, paths):\n",
    "    kNegInfinity = -np.inf\n",
    "    T = logProbs.shape[0]\n",
    "    L = targets.shape[0]\n",
    "    S = 2 * L + 1\n",
    "    alphas = np.full((2, S), kNegInfinity)\n",
    "    backPtr = np.full((T, S), -1, dtype=np.int8)\n",
    "    R = 0\n",
    "    for i in range(1, L):\n",
    "        if targets[i] == targets[i - 1]:\n",
    "            R += 1\n",
    "    if T < L + R:\n",
    "        raise ValueError(f\"targets length is too long for CTC. Found targets length: {T}, log_probs length: {L}, and number of repeats: {R}\")\n",
    "    start = 0 if T - (L + R) > 0 else 1\n",
    "    end = 1 if S == 1 else 2\n",
    "    for i in range(start, end):\n",
    "        labelIdx = blank if i % 2 == 0 else targets[i // 2]\n",
    "        alphas[0, i] = logProbs[0, labelIdx]\n",
    "    for t in range(1, T):\n",
    "        if T - t <= L + R:\n",
    "            if start % 2 == 1 and targets[start // 2] != targets[start // 2 + 1]:\n",
    "                start += 1\n",
    "            start += 1\n",
    "        if t <= L + R:\n",
    "            if end % 2 == 0 and end < 2 * L and targets[end // 2 - 1] != targets[end // 2]:\n",
    "                end += 1\n",
    "            end += 1\n",
    "        startloop = start\n",
    "        curIdxOffset = t % 2\n",
    "        prevIdxOffset = (t - 1) % 2\n",
    "        alphas[curIdxOffset, :] = kNegInfinity\n",
    "        if start == 0:\n",
    "            alphas[curIdxOffset, 0] = alphas[prevIdxOffset, 0] + logProbs[t, blank]\n",
    "            backPtr[t, 0] = 0\n",
    "            startloop += 1\n",
    "        for i in range(startloop, end):\n",
    "            x0 = alphas[prevIdxOffset, i]\n",
    "            x1 = alphas[prevIdxOffset, i - 1]\n",
    "            x2 = kNegInfinity\n",
    "            labelIdx = blank if i % 2 == 0 else targets[i // 2]\n",
    "            if i % 2 != 0 and i != 1 and targets[i // 2] != targets[i // 2 - 1]:\n",
    "                x2 = alphas[prevIdxOffset, i - 2]\n",
    "            result = 0.0\n",
    "            if x2 > x1 and x2 > x0:\n",
    "                result = x2\n",
    "                backPtr[t, i] = 2\n",
    "            elif x1 > x0 and x1 > x2:\n",
    "                result = x1\n",
    "                backPtr[t, i] = 1\n",
    "            else:\n",
    "                result = x0\n",
    "                backPtr[t, i] = 0\n",
    "            alphas[curIdxOffset, i] = result + logProbs[t, labelIdx]\n",
    "    idx1 = (T - 1) % 2\n",
    "    ltrIdx = S - 1 if alphas[idx1, S - 1] > alphas[idx1, S - 2] else S - 2\n",
    "    for t in range(T - 1, -1, -1):\n",
    "        lbl_idx = blank if ltrIdx % 2 == 0 else targets[ltrIdx // 2]\n",
    "        paths[t] = lbl_idx\n",
    "        ltrIdx -= backPtr[t, ltrIdx]\n",
    "\n",
    "def compute_np(logProbs, targets, inputLengths, targetLengths, blank):\n",
    "    if not isinstance(logProbs, np.ndarray):\n",
    "        raise ValueError(\"log_probs must be a numpy array\")\n",
    "    if not isinstance(targets, np.ndarray):\n",
    "        raise ValueError(\"targets must be a numpy array\")\n",
    "    if not np.issubdtype(logProbs.dtype, np.floating):\n",
    "        raise ValueError(\"log_probs must be float64, float32 or float16 (half) type\")\n",
    "    if not np.issubdtype(targets.dtype, np.integer):\n",
    "        raise ValueError(\"targets must be int32 or int64 type\")\n",
    "    if len(logProbs.shape) != 2:\n",
    "        raise ValueError(\"log_probs must be 2-D (input length, num classes)\")\n",
    "    if len(targets.shape) != 1:\n",
    "        raise ValueError(\"targets must be 1-D (target length,)\")\n",
    "    if np.ndim(inputLengths) != 0:\n",
    "        raise ValueError(\"input_lengths must be 0-D\")\n",
    "    if np.ndim(targetLengths) != 0:\n",
    "        raise ValueError(\"target_lengths must be 0-D\")\n",
    "    if blank < 0 or blank >= logProbs.shape[-1]:\n",
    "        raise ValueError(\"blank must be within [0, num classes)\")\n",
    "    if logProbs.shape[0] != inputLengths:\n",
    "        raise ValueError(\"input length mismatch\")\n",
    "    if targets.shape[0] != targetLengths:\n",
    "        raise ValueError(\"target length mismatch\")\n",
    "    T = logProbs.shape[0]\n",
    "    paths = np.zeros(T, dtype=targets.dtype)\n",
    "    forced_align_impl_np(logProbs, targets, blank, paths)\n",
    "    return paths, logProbs[np.arange(T), paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dabe765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2, 3], dtype=int32),\n",
       " array([-1.5425494, -1.3425493, -1.2425493], dtype=float32))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_np(np.asarray(logProbs), np.asarray(targets), np.asarray(input_lengths), np.asarray(target_lengths), blank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ac38c6",
   "metadata": {},
   "source": [
    "## Torch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f32edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.functional import forced_align\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62c3b700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1245398/3542591692.py:1: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  forced_align(torch.from_numpy(np.asarray(logProbs)), torch.from_numpy(np.asarray(targets)), torch.from_numpy(np.asarray(input_lengths)), torch.from_numpy(np.asarray(target_lengths)), blank)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 2, 3], dtype=torch.int32), tensor([-1.5425, -1.3425, -1.2425]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forced_align(torch.from_numpy(np.asarray(logProbs)), torch.from_numpy(np.asarray(targets)), torch.from_numpy(np.asarray(input_lengths)), torch.from_numpy(np.asarray(target_lengths)), blank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ce477",
   "metadata": {},
   "source": [
    "## Parellized jax implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1c3746e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def inner_loop_fn(t, i, startloop, end, prevIdxOffset, curIdxOffset, alphas, backPtr, logProbs, targets, kNegInfinity, blank):\n",
    "    \"\"\"\n",
    "    This function represents the logic inside the inner loop of the forced_align_impl_jnp function.\n",
    "    \n",
    "    Args:\n",
    "        t (int): The outer loop variable.\n",
    "        i (int): The inner loop variable.\n",
    "        startloop (int): The starting index of the inner loop.\n",
    "        end (int): The ending index of the inner loop.\n",
    "        prevIdxOffset (int): The offset index of the previous timestep.\n",
    "        curIdxOffset (int): The offset index of the current timestep.\n",
    "        alphas (jnp.ndarray): The alpha values.\n",
    "        backPtr (jnp.ndarray): The backpointer values.\n",
    "        logProbs (jnp.ndarray): The log probabilities.\n",
    "        targets (jnp.ndarray): The target values.\n",
    "        kNegInfinity (float): A constant representing negative infinity.\n",
    "        blank (int): The blank label.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[jnp.ndarray, jnp.ndarray]: The updated alpha values and backpointer values.\n",
    "    \"\"\"\n",
    "    print(f\"Input Shape of backPtr: {backPtr.shape}\")\n",
    "    print(f\"Input Shape of alphas: {alphas.shape}\")\n",
    "    x0 = alphas[prevIdxOffset, i]\n",
    "    x1 = alphas[prevIdxOffset, i - 1]\n",
    "    x2 = kNegInfinity\n",
    "    labelIdx = jnp.where(i % 2 == 0, blank, targets[i // 2])\n",
    "    condition = jnp.logical_and(jnp.logical_and(i % 2 != 0, i != 1), targets[i // 2] != targets[i // 2 - 1])\n",
    "    x2 = jnp.where(condition, alphas[prevIdxOffset, i - 2], kNegInfinity)\n",
    "    result = 0.0\n",
    "    \n",
    "    cond1 = jnp.logical_and(x2 > x1, x2 > x0)\n",
    "    cond2 = jnp.logical_and(~cond1, jnp.logical_and(x1 > x0, x1 > x2))\n",
    "\n",
    "    result = jnp.where(cond1, x2, jnp.where(cond2, x1, x0))\n",
    "    backPtr_val = jnp.where(cond1, 2, jnp.where(cond2, 1, 0))\n",
    "\n",
    "    print(f\"Output Shape of backPtr: {backPtr.shape}\")\n",
    "    backPtr = backPtr.at[t, i].set(backPtr_val)\n",
    "    \n",
    "    print(f\"Output Shape of alphas: {alphas.shape}\")\n",
    "    alphas = alphas.at[curIdxOffset, i].set(result + logProbs[t, labelIdx])\n",
    "    \n",
    "    return alphas, backPtr\n",
    "\n",
    "inner_loop_vmap = jax.vmap(inner_loop_fn, in_axes=(None, 0, None, None, None, None, None, None, None, None, None, None), out_axes=(0, 0))\n",
    "\n",
    "\n",
    "def forced_align_impl_jnp(logProbs, targets, blank, paths):\n",
    "    \"\"\"\n",
    "    This function performs forced alignment implementation using jax.numpy.\n",
    "    \n",
    "    Args:\n",
    "        logProbs (jnp.ndarray): The log probabilities.\n",
    "        targets (jnp.ndarray): The target values.\n",
    "        blank (int): The blank label.\n",
    "        paths (jnp.ndarray): The output paths.\n",
    "    \"\"\"\n",
    "    kNegInfinity = -jnp.inf\n",
    "    T = logProbs.shape[0]\n",
    "    L = targets.shape[0]\n",
    "    S = 2 * L + 1\n",
    "    alphas = jnp.full((2, S), kNegInfinity)\n",
    "    backPtr = jnp.full((T, S), -1, dtype=jnp.int8)\n",
    "    R = 0\n",
    "    for i in range(1, L):\n",
    "        if targets[i] == targets[i - 1]:\n",
    "            R += 1\n",
    "    if T < L + R:\n",
    "        raise ValueError(f\"targets length is too long for CTC. Found targets length: {T}, log_probs length: {L}, and number of repeats: {R}\")\n",
    "    start = 0 if T - (L + R) > 0 else 1\n",
    "    end = 1 if S == 1 else 2\n",
    "    for i in range(start, end):\n",
    "        labelIdx = blank if i % 2 == 0 else targets[i // 2]\n",
    "        alphas = alphas.at[0, i].set(logProbs[0, labelIdx])\n",
    "    for t in range(1, T):\n",
    "        if T - t <= L + R:\n",
    "            if start % 2 == 1 and targets[start // 2] != targets[start // 2 + 1]:\n",
    "                start += 1\n",
    "            start += 1\n",
    "        if t <= L + R:\n",
    "            if end % 2 == 0 and end < 2 * L and targets[end // 2 - 1] != targets[end // 2]:\n",
    "                end += 1\n",
    "            end += 1\n",
    "        startloop = start\n",
    "        curIdxOffset = t % 2\n",
    "        prevIdxOffset = (t - 1) % 2\n",
    "        alphas = alphas.at[curIdxOffset, :].set(kNegInfinity)\n",
    "        if start == 0:\n",
    "            alphas = alphas.at[curIdxOffset, 0].set(alphas[prevIdxOffset, 0] + logProbs[t, blank])\n",
    "            backPtr = backPtr.at[t, 0].set(0)\n",
    "            startloop += 1\n",
    "        alphas, backPtr = inner_loop_vmap(t, jnp.arange(startloop, end), startloop, end, prevIdxOffset, curIdxOffset, alphas, backPtr, logProbs, targets, kNegInfinity, blank)\n",
    "        \n",
    "        # find fix for these two lines\n",
    "        alphas = jnp.squeeze(alphas)\n",
    "        backPtr = jnp.squeeze(backPtr)\n",
    "\n",
    "    idx1 = (T - 1) % 2\n",
    "    ltrIdx = jnp.where(alphas[idx1, S - 1] > alphas[idx1, S - 2], S - 1, S - 2)\n",
    "    for t in range(T - 1, -1, -1):\n",
    "        lbl_idx = jnp.where(ltrIdx % 2 == 0, blank, targets[ltrIdx // 2])\n",
    "        paths = paths.at[t].set(jnp.array(lbl_idx))\n",
    "        ltrIdx -= backPtr[t, ltrIdx]\n",
    "    return paths, alphas, backPtr\n",
    "\n",
    "def compute_jnp(logProbs, targets, inputLengths, targetLengths, blank):\n",
    "    \"\"\"\n",
    "    This function performs computation using jax.numpy.\n",
    "    \n",
    "    Args:\n",
    "        logProbs (jnp.ndarray): The log probabilities.\n",
    "        targets (jnp.ndarray): The target values.\n",
    "        inputLengths (int): The input lengths.\n",
    "        targetLengths (int): The target lengths.\n",
    "        blank (int): The blank label.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: The output paths and the log probabilities for those paths.\n",
    "    \"\"\"\n",
    "    if not isinstance(logProbs, jnp.ndarray):\n",
    "        raise ValueError(\"log_probs must be a jax numpy array\")\n",
    "    if not isinstance(targets, jnp.ndarray):\n",
    "        raise ValueError(\"targets must be a jax numpy array\")\n",
    "    if not jnp.issubdtype(logProbs.dtype, jnp.floating):\n",
    "        raise ValueError(\"log_probs must be float64, float32 or float16 (half) type\")\n",
    "    if not jnp.issubdtype(targets.dtype, jnp.integer):\n",
    "        raise ValueError(\"targets must be int32 or int64 type\")\n",
    "    if len(logProbs.shape) != 2:\n",
    "        raise ValueError(\"log_probs must be 2-D (input length, num classes)\")\n",
    "    if len(targets.shape) != 1:\n",
    "        raise ValueError(\"targets must be 1-D (target length,)\")\n",
    "    if jnp.ndim(inputLengths) != 0:\n",
    "        raise ValueError(\"input_lengths must be 0-D\")\n",
    "    if jnp.ndim(targetLengths) != 0:\n",
    "        raise ValueError(\"target_lengths must be 0-D\")\n",
    "    if blank < 0 or blank >= logProbs.shape[-1]:\n",
    "        raise ValueError(\"blank must be within [0, num classes)\")\n",
    "    if logProbs.shape[0] != inputLengths:\n",
    "        raise ValueError(\"input length mismatch\")\n",
    "    if targets.shape[0] != targetLengths:\n",
    "        raise ValueError(\"target length mismatch\")\n",
    "    T = logProbs.shape[0]\n",
    "    paths = jnp.zeros(T, dtype=targets.dtype)\n",
    "    paths, alphas, backPtr = forced_align_impl_jnp(logProbs, targets, blank, paths)\n",
    "    return paths, logProbs[jnp.arange(T), paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "01b0166a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape of alphas: (2, 7), value: [[      -inf -1.5425494       -inf       -inf       -inf       -inf\n",
      "        -inf]\n",
      " [      -inf       -inf       -inf       -inf       -inf       -inf\n",
      "        -inf]]\n",
      "Output Shape of alphas: (2, 7), value: Traced<ShapedArray(float32[2,7], weak_type=True)>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([[[      -inf, -1.5425494,       -inf,       -inf,       -inf,\n",
      "               -inf,       -inf],\n",
      "        [      -inf,       -inf,       -inf, -2.8850987,       -inf,\n",
      "               -inf,       -inf]]], dtype=float32, weak_type=True)\n",
      "  batch_dim = 0\n",
      "Input Shape of alphas: (2, 7), value: [[      -inf       -inf       -inf       -inf       -inf       -inf\n",
      "        -inf]\n",
      " [      -inf       -inf       -inf -2.8850987       -inf       -inf\n",
      "        -inf]]\n",
      "Output Shape of alphas: (2, 7), value: Traced<ShapedArray(float32[2,7], weak_type=True)>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([[[      -inf,       -inf,       -inf,       -inf,       -inf,\n",
      "         -4.127648 ,       -inf],\n",
      "        [      -inf,       -inf,       -inf, -2.8850987,       -inf,\n",
      "               -inf,       -inf]]], dtype=float32, weak_type=True)\n",
      "  batch_dim = 0\n",
      "Shape of alphas: (2, 7), value: [[      -inf       -inf       -inf       -inf       -inf -4.127648\n",
      "        -inf]\n",
      " [      -inf       -inf       -inf -2.8850987       -inf       -inf\n",
      "        -inf]]\n",
      "Shape of ltrIdx: (), value: 5\n",
      "Shape of targets: (3,), value: [0 2 3]\n",
      "False, 3\n",
      "Shape of lbl_idx: ()\n",
      "Shape of paths[t]: ()\n",
      "Shape of backPtr[t]: (3, 7)\n",
      "False, 2\n",
      "Shape of lbl_idx: ()\n",
      "Shape of paths[t]: ()\n",
      "Shape of backPtr[t]: (3, 7)\n",
      "False, 0\n",
      "Shape of lbl_idx: ()\n",
      "Shape of paths[t]: ()\n",
      "Shape of backPtr[t]: (3, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Array([0, 2, 3], dtype=int32),\n",
       " Array([-1.5425494, -1.3425493, -1.2425493], dtype=float32))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test this with some random data\n",
    "logProbs = jnp.array([[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8], [0.9, 1.0, 1.1, 1.2]])\n",
    "targets = jnp.array([0, 2, 3])\n",
    "blank = 1\n",
    "\n",
    "logProbs = jax.nn.log_softmax(logProbs, axis=-1)\n",
    "\n",
    "input_lengths = jnp.array(logProbs.shape[0])\n",
    "target_lengths = jnp.array(targets.shape[0])\n",
    "\n",
    "compute_jnp(logProbs, targets, input_lengths, target_lengths, blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e18944f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1c8ae09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['targets.pt',\n",
       " 'target_lengths.pt',\n",
       " 'paths.pt',\n",
       " 'input_lengths.pt',\n",
       " 'emissions.pt']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Unzip the provided file\n",
    "with zipfile.ZipFile(\"forced_align_input_outputs.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"forced_align_input_outputs\")\n",
    "\n",
    "# Check the contents of the directory\n",
    "os.listdir(\"forced_align_input_outputs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0dc2bdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-7.3520811e-03, -2.7093369e+01, -2.7509064e+01, ...,\n",
       "         -8.7403002e+00, -1.1601903e+01, -1.1159496e+01],\n",
       "        [-1.3696853e-02, -2.7963503e+01, -2.8412813e+01, ...,\n",
       "         -9.0036783e+00, -1.1766139e+01, -1.0991915e+01],\n",
       "        [-3.1517904e-02, -2.9013901e+01, -2.9537155e+01, ...,\n",
       "         -9.1752405e+00, -1.2215663e+01, -1.1296188e+01],\n",
       "        ...,\n",
       "        [-8.4026694e-02, -2.5163204e+01, -2.5194981e+01, ...,\n",
       "         -7.7668262e+00, -8.7488461e+00, -8.5354090e+00],\n",
       "        [-8.3044618e-02, -2.5117912e+01, -2.5149914e+01, ...,\n",
       "         -7.6841059e+00, -8.7871141e+00, -8.6122017e+00],\n",
       "        [-9.2383891e-02, -2.5157015e+01, -2.5237972e+01, ...,\n",
       "         -7.7255855e+00, -8.7317905e+00, -8.4821301e+00]], dtype=float32),\n",
       " array([12,  4,  4, ..., 19,  4,  4], dtype=int32),\n",
       " array(10658),\n",
       " array(1648),\n",
       " array([0, 0, 0, ..., 0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the provided tensors\n",
    "logProbs = torch.load(\"forced_align_input_outputs/emissions.pt\")\n",
    "targets = torch.load(\"forced_align_input_outputs/targets.pt\")\n",
    "inputLengths = torch.load(\"forced_align_input_outputs/input_lengths.pt\")\n",
    "targetLengths = torch.load(\"forced_align_input_outputs/target_lengths.pt\")\n",
    "paths = torch.load(\"forced_align_input_outputs/paths.pt\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "logProbs_np = logProbs.numpy()\n",
    "targets_np = targets.numpy()\n",
    "inputLengths_np = inputLengths.numpy()\n",
    "targetLengths_np = targetLengths.numpy()\n",
    "paths_np = paths.numpy()\n",
    "\n",
    "blank = 0\n",
    "\n",
    "logProbs_np, targets_np, inputLengths_np, targetLengths_np, paths_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2d3a8f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3296"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_np.shape[0] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7ce9daf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  4,  0,  0,  0,  0,  0, 13,  0,  0,  5,  0,\n",
       "         0,  5,  0,  0,  7,  0,  0,  0,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0, 16,  0,  0,  0,  0,  0,  0,  0,  0, 16,  0,  0,  4,  0,  0,\n",
       "         9,  0,  0, 15,  0,  0,  0,  4,  0,  0,  4,  0,  0,  0,  0, 21,  0,  0,\n",
       "         0,  0,  4,  0,  0,  0,  0,  4,  0,  0, 12,  0,  0,  0,  0,  0, 14,  0,\n",
       "         0,  4,  0,  0,  0,  0,  0,  0,  0,  0], dtype=torch.int32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[415:515]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7e5dba64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape of backPtr: (10658, 3297)\n",
      "Input Shape of alphas: (2, 3297)\n",
      "Output Shape of backPtr: (10658, 3297)\n",
      "Output Shape of alphas: (2, 3297)\n",
      "Input Shape of backPtr: (3, 10658, 3297)\n",
      "Input Shape of alphas: (3, 2, 3297)\n",
      "Output Shape of backPtr: (3, 10658, 3297)\n",
      "Output Shape of alphas: (3, 2, 3297)\n",
      "Input Shape of backPtr: (4, 3, 10658, 3297)\n",
      "Input Shape of alphas: (4, 3, 2, 3297)\n",
      "Output Shape of backPtr: (4, 3, 10658, 3297)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incompatible shapes for broadcasting: (2, 3297) and requested shape (10658, 3297)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [101], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m paths_result, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_jnp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogProbs_np\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets_np\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputLengths_np\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargetLengths_np\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblank\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [100], line 146\u001b[0m, in \u001b[0;36mcompute_jnp\u001b[0;34m(logProbs, targets, inputLengths, targetLengths, blank)\u001b[0m\n\u001b[1;32m    144\u001b[0m T \u001b[38;5;241m=\u001b[39m logProbs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    145\u001b[0m paths \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mzeros(T, dtype\u001b[38;5;241m=\u001b[39mtargets\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 146\u001b[0m paths, alphas, backPtr \u001b[38;5;241m=\u001b[39m \u001b[43mforced_align_impl_jnp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogProbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m paths, logProbs[jnp\u001b[38;5;241m.\u001b[39marange(T), paths]\n",
      "Cell \u001b[0;32mIn [100], line 96\u001b[0m, in \u001b[0;36mforced_align_impl_jnp\u001b[0;34m(logProbs, targets, blank, paths)\u001b[0m\n\u001b[1;32m     94\u001b[0m     backPtr \u001b[38;5;241m=\u001b[39m backPtr\u001b[38;5;241m.\u001b[39mat[t, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m     startloop \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 96\u001b[0m alphas, backPtr \u001b[38;5;241m=\u001b[39m \u001b[43minner_loop_vmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstartloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevIdxOffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurIdxOffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malphas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackPtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogProbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkNegInfinity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblank\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m alphas \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39msqueeze(alphas)\n\u001b[1;32m     98\u001b[0m backPtr \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39msqueeze(backPtr)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn [100], line 42\u001b[0m, in \u001b[0;36minner_loop_fn\u001b[0;34m(t, i, startloop, end, prevIdxOffset, curIdxOffset, alphas, backPtr, logProbs, targets, kNegInfinity, blank)\u001b[0m\n\u001b[1;32m     39\u001b[0m backPtr_val \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mwhere(cond1, \u001b[38;5;241m2\u001b[39m, jnp\u001b[38;5;241m.\u001b[39mwhere(cond2, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput Shape of backPtr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackPtr\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m backPtr \u001b[38;5;241m=\u001b[39m \u001b[43mbackPtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackPtr_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput Shape of alphas: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malphas\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m alphas \u001b[38;5;241m=\u001b[39m alphas\u001b[38;5;241m.\u001b[39mat[curIdxOffset, i]\u001b[38;5;241m.\u001b[39mset(result \u001b[38;5;241m+\u001b[39m logProbs[t, labelIdx])\n",
      "File \u001b[0;32m~/.venv310/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:485\u001b[0m, in \u001b[0;36mallow_pass_by_position_with_warning.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs[:n_positional], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconverted_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 485\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv310/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:532\u001b[0m, in \u001b[0;36m_IndexUpdateRef.set\u001b[0;34m(self, values, indices_are_sorted, unique_indices, mode)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;129m@allow_pass_by_position_with_warning\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, values, \u001b[38;5;241m*\u001b[39m, indices_are_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, unique_indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    524\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    525\u001b[0m   \u001b[38;5;124;03m\"\"\"Pure equivalent of ``x[idx] = y``.\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \n\u001b[1;32m    527\u001b[0m \u001b[38;5;124;03m  Returns the value of ``x`` that would result from the NumPy-style\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;124;03m  See :mod:`jax.ops` for details.\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scatter_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mindices_are_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices_are_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43munique_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv310/lib/python3.10/site-packages/jax/_src/ops/scatter.py:76\u001b[0m, in \u001b[0;36m_scatter_update\u001b[0;34m(x, idx, y, scatter_op, indices_are_sorted, unique_indices, mode, normalize_indices)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# XLA gathers and scatters are very similar in structure; the scatter logic\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# is more or less a transpose of the gather equivalent.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m treedef, static_idx, dynamic_idx \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39m_split_index_for_jit(idx, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_scatter_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscatter_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreedef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mindices_are_sorted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mnormalize_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv310/lib/python3.10/site-packages/jax/_src/ops/scatter.py:109\u001b[0m, in \u001b[0;36m_scatter_impl\u001b[0;34m(x, y, scatter_op, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, normalize_indices)\u001b[0m\n\u001b[1;32m    106\u001b[0m x, y \u001b[38;5;241m=\u001b[39m promote_dtypes(x, y)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Broadcast `y` to the slice output shape.\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Collapse any `None`/`jnp.newaxis` dimensions.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m y \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39msqueeze(y, axis\u001b[38;5;241m=\u001b[39mindexer\u001b[38;5;241m.\u001b[39mnewaxis_dims)\n",
      "File \u001b[0;32m~/.venv310/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:1173\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[0;34m(array, shape)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;129m@util\u001b[39m\u001b[38;5;241m.\u001b[39m_wraps(np\u001b[38;5;241m.\u001b[39mbroadcast_to, lax_description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;124mThe JAX version does not necessarily return a view of the input.\u001b[39m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroadcast_to\u001b[39m(array: ArrayLike, shape: Shape) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[0;32m-> 1173\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_broadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv310/lib/python3.10/site-packages/jax/_src/numpy/util.py:401\u001b[0m, in \u001b[0;36m_broadcast_to\u001b[0;34m(arr, shape)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nlead \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compatible:\n\u001b[1;32m    400\u001b[0m   msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible shapes for broadcasting: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and requested shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 401\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(arr_shape, shape))\n\u001b[1;32m    402\u001b[0m diff, \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39msymbolic_equal_dim(arr_d, shape_d)\n\u001b[1;32m    403\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m arr_d, shape_d \u001b[38;5;129;01min\u001b[39;00m safe_zip(arr_shape, shape_tail)))\n\u001b[1;32m    404\u001b[0m new_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(nlead)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(nlead \u001b[38;5;241m+\u001b[39m diff)\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: (2, 3297) and requested shape (10658, 3297)"
     ]
    }
   ],
   "source": [
    "paths_result, _ = compute_jnp(jnp.asarray(logProbs_np), jnp.asarray(targets_np), jnp.asarray(inputLengths_np), jnp.asarray(targetLengths_np), blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f668fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
