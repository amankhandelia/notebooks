{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook intends to replicate all the examples from the [pjit blog](https://irhum.github.io/blog/pjit/) from [`Irhum`](https://github.com/irhum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from jax.experimental import mesh_utils\n",
    "from jax.sharding import PositionalSharding, NamedSharding, Mesh\n",
    "\n",
    "from jax.sharding import PartitionSpec as P\n",
    "\n",
    "if len(jax.local_devices()) < 8:\n",
    "    raise Exception(\"Notebook requires 8 devices to run\")\n",
    "\n",
    "from jax_smi import initialise_tracking\n",
    "initialise_tracking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = mesh_utils.create_device_mesh((4, 2))\n",
    "mesh = Mesh(devices, axis_names=('a', 'b'))\n",
    "key = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Case 1: Inner Axes](https://irhum.github.io/blog/pjit/#case-1-inner-axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "# create a vector of 1, 2, 3, 4\n",
    "v = jnp.arange(1, 5)\n",
    "# repeat the vector 16 times along the first axis\n",
    "x = jnp.repeat(v[:, None], 16, axis=1)\n",
    "\n",
    "x = jnp.asarray(x, dtype=\"f2\")\n",
    "y = jnp.copy(x).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌───────────────────┬───────────────────┬───────────────────┬──────────────────┐\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│        TPU        │        TPU        │        TPU        │        T…        │\n",
       "│        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>        │        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>        │        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>        │        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>…        │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "└───────────────────┴───────────────────┴───────────────────┴──────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌───────────────────┬───────────────────┬───────────────────┬──────────────────┐\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│        TPU        │        TPU        │        TPU        │        T…        │\n",
       "│        \u001b[1;36m0\u001b[0m,\u001b[1;36m1\u001b[0m        │        \u001b[1;36m2\u001b[0m,\u001b[1;36m3\u001b[0m        │        \u001b[1;36m6\u001b[0m,\u001b[1;36m7\u001b[0m        │        \u001b[1;36m4\u001b[0m…        │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "└───────────────────┴───────────────────┴───────────────────┴──────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌───────┐\n",
       "│TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>│\n",
       "├───────┤\n",
       "│TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>│\n",
       "├───────┤\n",
       "│TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>│\n",
       "├───────┤\n",
       "│TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>│\n",
       "└───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌───────┐\n",
       "│TPU \u001b[1;36m0\u001b[0m,\u001b[1;36m1\u001b[0m│\n",
       "├───────┤\n",
       "│TPU \u001b[1;36m2\u001b[0m,\u001b[1;36m3\u001b[0m│\n",
       "├───────┤\n",
       "│TPU \u001b[1;36m6\u001b[0m,\u001b[1;36m7\u001b[0m│\n",
       "├───────┤\n",
       "│TPU \u001b[1;36m4\u001b[0m,\u001b[1;36m5\u001b[0m│\n",
       "└───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = jax.device_put(x, NamedSharding(mesh, P(None, 'a')))\n",
    "jax.debug.visualize_array_sharding(x)\n",
    "y = jax.device_put(y, NamedSharding(mesh, P('a', None)))\n",
    "jax.debug.visualize_array_sharding(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌───────────────────────┐\n",
       "│                       │\n",
       "│                       │\n",
       "│                       │\n",
       "│                       │\n",
       "│  TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>  │\n",
       "│                       │\n",
       "│                       │\n",
       "│                       │\n",
       "│                       │\n",
       "└───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌───────────────────────┐\n",
       "│                       │\n",
       "│                       │\n",
       "│                       │\n",
       "│                       │\n",
       "│  TPU \u001b[1;36m0\u001b[0m,\u001b[1;36m1\u001b[0m,\u001b[1;36m2\u001b[0m,\u001b[1;36m3\u001b[0m,\u001b[1;36m4\u001b[0m,\u001b[1;36m5\u001b[0m,\u001b[1;36m6\u001b[0m,\u001b[1;36m7\u001b[0m  │\n",
       "│                       │\n",
       "│                       │\n",
       "│                       │\n",
       "│                       │\n",
       "└───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 16.  32.  48.  64.]\n",
      " [ 32.  64.  96. 128.]\n",
      " [ 48.  96. 144. 192.]\n",
      " [ 64. 128. 192. 256.]]\n"
     ]
    }
   ],
   "source": [
    "z = x@y\n",
    "jax.debug.visualize_array_sharding(z)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HloModule jit_matmul, is_scheduled=true, entry_computation_layout={(f32[4,4]{1,0:T(4,128)}, f32[4,4]{1,0:T(4,128)})->f32[4,4]{1,0:T(4,128)}}, allow_spmd_sharding_propagation_to_output={true}\n",
      "\n",
      "%add (x: f32[], y: f32[]) -> f32[] {\n",
      "  %y = f32[]{:T(256)} parameter(1)\n",
      "  %x = f32[]{:T(256)} parameter(0)\n",
      "  ROOT %add = f32[]{:T(256)} add(f32[]{:T(256)} %x, f32[]{:T(256)} %y)\n",
      "}\n",
      "\n",
      "%bitcast_fusion (bf16input: f32[4,4]) -> f32[4,4] {\n",
      "  %bf16input = f32[4,4]{1,0:T(4,128)} parameter(0)\n",
      "  ROOT %bitcast = f32[4,4]{1,0:T(4,128)} bitcast(f32[4,4]{1,0:T(4,128)} %bf16input)\n",
      "}\n",
      "\n",
      "%bitcast_fusion.1 (bf16input.1: f32[4,4]) -> f32[4,4] {\n",
      "  %bf16input.1 = f32[4,4]{1,0:T(4,128)} parameter(0)\n",
      "  ROOT %bitcast.1 = f32[4,4]{1,0:T(4,128)} bitcast(f32[4,4]{1,0:T(4,128)} %bf16input.1)\n",
      "}\n",
      "\n",
      "%fused_computation (param_0: f32[4,4], param_1: f32[4,4]) -> f32[4,4] {\n",
      "  %param_0 = f32[4,4]{1,0:T(4,128)} parameter(0)\n",
      "  %fusion.1 = f32[4,4]{1,0:T(4,128)} fusion(f32[4,4]{1,0:T(4,128)} %param_0), kind=kLoop, calls=%bitcast_fusion\n",
      "  %param_1 = f32[4,4]{1,0:T(4,128)} parameter(1)\n",
      "  %fusion.2 = f32[4,4]{1,0:T(4,128)} fusion(f32[4,4]{1,0:T(4,128)} %param_1), kind=kLoop, calls=%bitcast_fusion.1\n",
      "  ROOT %convolution.1 = f32[4,4]{1,0:T(4,128)} convolution(f32[4,4]{1,0:T(4,128)} %fusion.1, f32[4,4]{1,0:T(4,128)} %fusion.2), dim_labels=bf_io->bf, metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3221403/1716122660.py\" source_line=1}\n",
      "}\n",
      "\n",
      "ENTRY %main.4_spmd (param: f32[4,4], param.1: f32[4,4]) -> f32[4,4] {\n",
      "  %param.1 = f32[4,4]{1,0:T(4,128)} parameter(1), sharding={devices=[4,1,2]0,1,2,3,4,5,6,7 last_tile_dim_replicate}\n",
      "  %param = f32[4,4]{1,0:T(4,128)} parameter(0), sharding={devices=[1,4,2]0,1,2,3,4,5,6,7 last_tile_dim_replicate}\n",
      "  %fusion = f32[4,4]{1,0:T(4,128)} fusion(f32[4,4]{1,0:T(4,128)} %param, f32[4,4]{1,0:T(4,128)} %param.1), kind=kOutput, calls=%fused_computation, metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3221403/1716122660.py\" source_line=1}, backend_config={\"flag_configs\":[],\"window_config\":{\"kernel_window_bounds\":[\"1\",\"1\"],\"output_window_bounds\":[\"1\",\"1\"],\"input_window_bounds\":[\"1\",\"1\"],\"estimated_cycles\":\"956\",\"iteration_bounds\":[\"1\",\"1\",\"1\"]},\"scoped_memory_configs\":[]}\n",
      "  ROOT %all-reduce = f32[4,4]{1,0:T(4,128)} all-reduce(f32[4,4]{1,0:T(4,128)} %fusion), channel_id=1, replica_groups={{0,2,4,6},{1,3,5,7}}, use_global_device_ids=true, to_apply=%add, metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3221403/1716122660.py\" source_line=1}, backend_config={\"flag_configs\":[],\"barrier_config\":{\"barrier_type\":\"CUSTOM\",\"id\":\"0\"},\"scoped_memory_configs\":[{\"memory_space\":\"0\",\"offset\":\"0\",\"size\":\"67108864\"}],\"collective_algorithm_config\":{\"emitter\":\"SinglePhaseRingSumEmitter\"}}\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(jnp.matmul.lower(x, y).compile().as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442 µs ± 88.5 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 -r 10 jnp.matmul(x, y).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Case 1B: Mesh-axes mismatch](https://irhum.github.io/blog/pjit/#case-1b-mesh-axes-mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "# create a vector of 1, 2, 3, 4\n",
    "v = jnp.arange(1, 5)\n",
    "# repeat the vector 16 times along the first axis\n",
    "x = jnp.repeat(v[:, None], 16, axis=1)\n",
    "\n",
    "x = jnp.asarray(x, dtype=\"f2\")\n",
    "y = jnp.copy(x).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌───────────────────┬───────────────────┬───────────────────┬──────────────────┐\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│        TPU        │        TPU        │        TPU        │        T…        │\n",
       "│        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>        │        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>        │        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>        │        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>…        │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "└───────────────────┴───────────────────┴───────────────────┴──────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌───────────────────┬───────────────────┬───────────────────┬──────────────────┐\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│        TPU        │        TPU        │        TPU        │        T…        │\n",
       "│        \u001b[1;36m0\u001b[0m,\u001b[1;36m1\u001b[0m        │        \u001b[1;36m2\u001b[0m,\u001b[1;36m3\u001b[0m        │        \u001b[1;36m6\u001b[0m,\u001b[1;36m7\u001b[0m        │        \u001b[1;36m4\u001b[0m…        │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "│                   │                   │                   │                  │\n",
       "└───────────────────┴───────────────────┴───────────────────┴──────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌───────────┐\n",
       "│           │\n",
       "│TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>│\n",
       "│           │\n",
       "│           │\n",
       "├───────────┤\n",
       "│           │\n",
       "│TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>│\n",
       "│           │\n",
       "│           │\n",
       "└───────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌───────────┐\n",
       "│           │\n",
       "│TPU \u001b[1;36m0\u001b[0m,\u001b[1;36m2\u001b[0m,\u001b[1;36m4\u001b[0m,\u001b[1;36m6\u001b[0m│\n",
       "│           │\n",
       "│           │\n",
       "├───────────┤\n",
       "│           │\n",
       "│TPU \u001b[1;36m1\u001b[0m,\u001b[1;36m3\u001b[0m,\u001b[1;36m5\u001b[0m,\u001b[1;36m7\u001b[0m│\n",
       "│           │\n",
       "│           │\n",
       "└───────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = jax.device_put(x, NamedSharding(mesh, P(None, 'a')))\n",
    "jax.debug.visualize_array_sharding(x)\n",
    "y = jax.device_put(y, NamedSharding(mesh, P('b', None)))\n",
    "jax.debug.visualize_array_sharding(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌───────────────────────┐\n",
       "│                       │\n",
       "│                       │\n",
       "│                       │\n",
       "│                       │\n",
       "│  TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>  │\n",
       "│                       │\n",
       "│                       │\n",
       "│                       │\n",
       "│                       │\n",
       "└───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌───────────────────────┐\n",
       "│                       │\n",
       "│                       │\n",
       "│                       │\n",
       "│                       │\n",
       "│  TPU \u001b[1;36m0\u001b[0m,\u001b[1;36m1\u001b[0m,\u001b[1;36m2\u001b[0m,\u001b[1;36m3\u001b[0m,\u001b[1;36m4\u001b[0m,\u001b[1;36m5\u001b[0m,\u001b[1;36m6\u001b[0m,\u001b[1;36m7\u001b[0m  │\n",
       "│                       │\n",
       "│                       │\n",
       "│                       │\n",
       "│                       │\n",
       "└───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = x@y\n",
    "jax.debug.visualize_array_sharding(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 16.,  32.,  48.,  64.],\n",
       "       [ 32.,  64.,  96., 128.],\n",
       "       [ 48.,  96., 144., 192.],\n",
       "       [ 64., 128., 192., 256.]], dtype=float16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HloModule jit_matmul, is_scheduled=true, entry_computation_layout={(f16[4,4]{1,0:T(4,128)(2,1)}, f16[8,4]{0,1:T(4,128)(2,1)})->f16[4,4]{1,0:T(4,128)(2,1)}}, allow_spmd_sharding_propagation_to_output={true}\n",
      "\n",
      "%bitcast_fusion (bf16input: f16[16,4]) -> f16[16,4] {\n",
      "  %bf16input = f16[16,4]{1,0:T(8,128)(2,1)} parameter(0)\n",
      "  ROOT %bitcast.7 = f16[16,4]{1,0:T(8,128)(2,1)} bitcast(f16[16,4]{1,0:T(8,128)(2,1)} %bf16input)\n",
      "}\n",
      "\n",
      "%bitcast_fusion.1 (bf16input.1: f16[16,4]) -> f16[16,4] {\n",
      "  %bf16input.1 = f16[16,4]{0,1:T(4,128)(2,1)} parameter(0)\n",
      "  ROOT %bitcast.8 = f16[16,4]{0,1:T(4,128)(2,1)} bitcast(f16[16,4]{0,1:T(4,128)(2,1)} %bf16input.1)\n",
      "}\n",
      "\n",
      "%fused_computation (param_0: f16[16,4], param_1: f16[16,4]) -> f16[4,4] {\n",
      "  %param_0 = f16[16,4]{1,0:T(8,128)(2,1)} parameter(0)\n",
      "  %fusion.1 = f16[16,4]{1,0:T(8,128)(2,1)} fusion(f16[16,4]{1,0:T(8,128)(2,1)} %param_0), kind=kLoop, calls=%bitcast_fusion\n",
      "  %param_1 = f16[16,4]{0,1:T(4,128)(2,1)} parameter(1)\n",
      "  %fusion.2 = f16[16,4]{0,1:T(4,128)(2,1)} fusion(f16[16,4]{0,1:T(4,128)(2,1)} %param_1), kind=kLoop, calls=%bitcast_fusion.1\n",
      "  ROOT %convolution.1 = f16[4,4]{1,0:T(4,128)(2,1)} convolution(f16[16,4]{1,0:T(8,128)(2,1)} %fusion.1, f16[16,4]{0,1:T(4,128)(2,1)} %fusion.2), dim_labels=fb_io->bf, metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3268342/1716122660.py\" source_line=1}\n",
      "}\n",
      "\n",
      "ENTRY %main.4_spmd (param: f16[4,4], param.1: f16[8,4]) -> f16[4,4] {\n",
      "  %param.1 = f16[8,4]{0,1:T(4,128)(2,1)} parameter(1), sharding={devices=[2,1,4]0,2,4,6,1,3,5,7 last_tile_dim_replicate}\n",
      "  %param = f16[4,4]{1,0:T(4,128)(2,1)} parameter(0), sharding={devices=[1,4,2]0,1,2,3,4,5,6,7 last_tile_dim_replicate}\n",
      "  %bitcast.3 = f16[1,8,4]{1,2,0:T(4,128)(2,1)} bitcast(f16[8,4]{0,1:T(4,128)(2,1)} %param.1)\n",
      "  %all-gather.3 = f16[2,8,4]{1,2,0:T(4,128)(2,1)} all-gather(f16[1,8,4]{1,2,0:T(4,128)(2,1)} %bitcast.3), channel_id=2, replica_groups={{0,1},{2,3},{4,5},{6,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3268342/1716122660.py\" source_line=1}, backend_config={\"flag_configs\":[],\"barrier_config\":{\"barrier_type\":\"CUSTOM\",\"id\":\"1\"},\"scoped_memory_configs\":[],\"collective_algorithm_config\":{\"emitter\":\"1DAllGatherOnMajorDim\",\"debug\":\"\\ngroup_size = 2\\nper_stride_size = 1024 bytes\\nshard_size = 1024 bytes\"}}\n",
      "  %copy.4 = f16[2,8,4]{1,0,2:T(4,128)(2,1)} copy(f16[2,8,4]{1,2,0:T(4,128)(2,1)} %all-gather.3), metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3268342/1716122660.py\" source_line=1}, backend_config={\"flag_configs\":[],\"window_config\":{\"kernel_window_bounds\":[],\"output_window_bounds\":[\"4\",\"1\",\"1\"],\"input_window_bounds\":[],\"estimated_cycles\":\"286\",\"iteration_bounds\":[\"1\",\"1\",\"1\"]},\"scoped_memory_configs\":[]}\n",
      "  %reshape.3 = f16[16,4]{0,1:T(4,128)(2,1)} reshape(f16[2,8,4]{1,0,2:T(4,128)(2,1)} %copy.4), backend_config={\"flag_configs\":[],\"integer_config\":{\"integer\":\"64\"},\"scoped_memory_configs\":[]}\n",
      "  %copy.2 = f16[4,4]{0,1:T(4,128)(2,1)} copy(f16[4,4]{1,0:T(4,128)(2,1)} %param), sharding={devices=[1,4,2]0,1,2,3,4,5,6,7 last_tile_dim_replicate}, backend_config={\"flag_configs\":[],\"window_config\":{\"kernel_window_bounds\":[],\"output_window_bounds\":[\"1\",\"1\"],\"input_window_bounds\":[\"1\",\"1\"],\"estimated_cycles\":\"566\",\"iteration_bounds\":[\"1\",\"1\"]},\"scoped_memory_configs\":[]}\n",
      "  %bitcast.1 = f16[1,4,4]{2,1,0:T(4,128)(2,1)} bitcast(f16[4,4]{0,1:T(4,128)(2,1)} %copy.2)\n",
      "  %all-gather.2 = f16[4,4,4]{2,1,0:T(4,128)(2,1)} all-gather(f16[1,4,4]{2,1,0:T(4,128)(2,1)} %bitcast.1), channel_id=1, replica_groups={{0,2,4,6},{1,3,5,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3268342/1716122660.py\" source_line=1}, backend_config={\"flag_configs\":[],\"barrier_config\":{\"barrier_type\":\"CUSTOM\",\"id\":\"0\"},\"scoped_memory_configs\":[],\"collective_algorithm_config\":{\"emitter\":\"1DAllGatherOnMajorDim\",\"debug\":\"\\ngroup_size = 4\\nper_stride_size = 1024 bytes\\nshard_size = 1024 bytes\"}}\n",
      "  %bitcast.2 = f16[16,4]{1,0:T(8,128)(2,1)} bitcast(f16[4,4,4]{2,1,0:T(4,128)(2,1)} %all-gather.2)\n",
      "  ROOT %fusion = f16[4,4]{1,0:T(4,128)(2,1)} fusion(f16[16,4]{1,0:T(8,128)(2,1)} %bitcast.2, f16[16,4]{0,1:T(4,128)(2,1)} %reshape.3), kind=kOutput, calls=%fused_computation, metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3268342/1716122660.py\" source_line=1}, backend_config={\"flag_configs\":[],\"window_config\":{\"kernel_window_bounds\":[\"1\",\"1\"],\"output_window_bounds\":[\"1\",\"1\"],\"input_window_bounds\":[\"2\",\"1\"],\"estimated_cycles\":\"984\",\"iteration_bounds\":[\"1\",\"1\",\"1\"]},\"scoped_memory_configs\":[]}\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(jnp.matmul.lower(x, y).compile().as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503 µs ± 73.8 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 -r 10 jnp.matmul(x, y).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Case 2: Outer Axes](https://irhum.github.io/blog/pjit/#case-2-outer-axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "# create a vector of 1, 2, 3, 4\n",
    "v = jnp.arange(1, 5)\n",
    "# repeat the vector 16 times along the first axis\n",
    "x = jnp.repeat(v[:, None], 16, axis=1)\n",
    "\n",
    "x = jnp.asarray(x, dtype=\"f2\")\n",
    "y = jnp.copy(x).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌───────────────────────┬───────────────────────┬───────────────────────┬───────────────────────┐\n",
       "│                       │                       │                       │                       │\n",
       "│         TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>         │         TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>         │         TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>         │         TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>         │\n",
       "│                       │                       │                       │                       │\n",
       "│                       │                       │                       │                       │\n",
       "├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┤\n",
       "│                       │                       │                       │                       │\n",
       "│         TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>         │         TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>         │         TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>         │         TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>         │\n",
       "│                       │                       │                       │                       │\n",
       "│                       │                       │                       │                       │\n",
       "└───────────────────────┴───────────────────────┴───────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌───────────────────────┬───────────────────────┬───────────────────────┬───────────────────────┐\n",
       "│                       │                       │                       │                       │\n",
       "│         TPU \u001b[1;36m0\u001b[0m         │         TPU \u001b[1;36m2\u001b[0m         │         TPU \u001b[1;36m6\u001b[0m         │         TPU \u001b[1;36m4\u001b[0m         │\n",
       "│                       │                       │                       │                       │\n",
       "│                       │                       │                       │                       │\n",
       "├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┤\n",
       "│                       │                       │                       │                       │\n",
       "│         TPU \u001b[1;36m1\u001b[0m         │         TPU \u001b[1;36m3\u001b[0m         │         TPU \u001b[1;36m7\u001b[0m         │         TPU \u001b[1;36m5\u001b[0m         │\n",
       "│                       │                       │                       │                       │\n",
       "│                       │                       │                       │                       │\n",
       "└───────────────────────┴───────────────────────┴───────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = jax.device_put(x, NamedSharding(mesh, P('b', 'a')))\n",
    "jax.debug.visualize_array_sharding(x, max_width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌───────────┐\n",
       "│           │\n",
       "│TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>│\n",
       "│           │\n",
       "│           │\n",
       "├───────────┤\n",
       "│           │\n",
       "│TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>│\n",
       "│           │\n",
       "│           │\n",
       "└───────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌───────────┐\n",
       "│           │\n",
       "│TPU \u001b[1;36m0\u001b[0m,\u001b[1;36m2\u001b[0m,\u001b[1;36m4\u001b[0m,\u001b[1;36m6\u001b[0m│\n",
       "│           │\n",
       "│           │\n",
       "├───────────┤\n",
       "│           │\n",
       "│TPU \u001b[1;36m1\u001b[0m,\u001b[1;36m3\u001b[0m,\u001b[1;36m5\u001b[0m,\u001b[1;36m7\u001b[0m│\n",
       "│           │\n",
       "│           │\n",
       "└───────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = jax.device_put(y, NamedSharding(mesh, P('b', None)))\n",
    "jax.debug.visualize_array_sharding(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌───────────────────────┐\n",
       "│                       │\n",
       "│      TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>      │\n",
       "│                       │\n",
       "│                       │\n",
       "├───────────────────────┤\n",
       "│                       │\n",
       "│      TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>      │\n",
       "│                       │\n",
       "│                       │\n",
       "└───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌───────────────────────┐\n",
       "│                       │\n",
       "│      TPU \u001b[1;36m0\u001b[0m,\u001b[1;36m2\u001b[0m,\u001b[1;36m4\u001b[0m,\u001b[1;36m6\u001b[0m      │\n",
       "│                       │\n",
       "│                       │\n",
       "├───────────────────────┤\n",
       "│                       │\n",
       "│      TPU \u001b[1;36m1\u001b[0m,\u001b[1;36m3\u001b[0m,\u001b[1;36m5\u001b[0m,\u001b[1;36m7\u001b[0m      │\n",
       "│                       │\n",
       "│                       │\n",
       "└───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 16.  32.  48.  64.]\n",
      " [ 32.  64.  96. 128.]\n",
      " [ 48.  96. 144. 192.]\n",
      " [ 64. 128. 192. 256.]]\n"
     ]
    }
   ],
   "source": [
    "z = x@y\n",
    "jax.debug.visualize_array_sharding(z)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HloModule jit_matmul, is_scheduled=true, entry_computation_layout={(f16[2,4]{1,0:T(4,128)(2,1)}, f16[8,4]{0,1:T(4,128)(2,1)})->f16[2,4]{1,0:T(4,128)(2,1)}}, allow_spmd_sharding_propagation_to_output={true}\n",
      "\n",
      "%bitcast_fusion (bf16input: f16[16,2]) -> f16[16,2] {\n",
      "  %bf16input = f16[16,2]{1,0:T(8,128)(2,1)} parameter(0)\n",
      "  ROOT %bitcast.7 = f16[16,2]{1,0:T(8,128)(2,1)} bitcast(f16[16,2]{1,0:T(8,128)(2,1)} %bf16input)\n",
      "}\n",
      "\n",
      "%bitcast_fusion.1 (bf16input.1: f16[16,4]) -> f16[16,4] {\n",
      "  %bf16input.1 = f16[16,4]{0,1:T(4,128)(2,1)} parameter(0)\n",
      "  ROOT %bitcast.8 = f16[16,4]{0,1:T(4,128)(2,1)} bitcast(f16[16,4]{0,1:T(4,128)(2,1)} %bf16input.1)\n",
      "}\n",
      "\n",
      "%fused_computation (param_0: f16[16,2], param_1: f16[16,4]) -> f16[2,4] {\n",
      "  %param_0 = f16[16,2]{1,0:T(8,128)(2,1)} parameter(0)\n",
      "  %fusion.1 = f16[16,2]{1,0:T(8,128)(2,1)} fusion(f16[16,2]{1,0:T(8,128)(2,1)} %param_0), kind=kLoop, calls=%bitcast_fusion\n",
      "  %param_1 = f16[16,4]{0,1:T(4,128)(2,1)} parameter(1)\n",
      "  %fusion.2 = f16[16,4]{0,1:T(4,128)(2,1)} fusion(f16[16,4]{0,1:T(4,128)(2,1)} %param_1), kind=kLoop, calls=%bitcast_fusion.1\n",
      "  ROOT %convolution.1 = f16[2,4]{1,0:T(4,128)(2,1)} convolution(f16[16,2]{1,0:T(8,128)(2,1)} %fusion.1, f16[16,4]{0,1:T(4,128)(2,1)} %fusion.2), dim_labels=fb_io->bf, metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3316818/197889973.py\" source_line=1}\n",
      "}\n",
      "\n",
      "ENTRY %main.4_spmd (param: f16[2,4], param.1: f16[8,4]) -> f16[2,4] {\n",
      "  %param.1 = f16[8,4]{0,1:T(4,128)(2,1)} parameter(1), sharding={devices=[2,1,4]0,2,4,6,1,3,5,7 last_tile_dim_replicate}\n",
      "  %param = f16[2,4]{1,0:T(4,128)(2,1)} parameter(0), sharding={devices=[2,4]0,2,4,6,1,3,5,7}\n",
      "  %collective-permute = f16[8,4]{0,1:T(4,128)(2,1)} collective-permute(f16[8,4]{0,1:T(4,128)(2,1)} %param.1), channel_id=1, source_target_pairs={{0,0},{2,1},{4,2},{6,3},{1,4},{3,5},{5,6},{7,7}}, metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3316818/197889973.py\" source_line=1}, backend_config={\"flag_configs\":[],\"barrier_config\":{\"barrier_type\":\"CUSTOM\",\"id\":\"2\"},\"scoped_memory_configs\":[],\"collective_algorithm_config\":{\"emitter\":\"CollectivePermuteEmitter\"}}\n",
      "  %bitcast.3 = f16[1,8,4]{1,2,0:T(4,128)(2,1)} bitcast(f16[8,4]{0,1:T(4,128)(2,1)} %collective-permute)\n",
      "  %all-gather.3 = f16[2,8,4]{1,2,0:T(4,128)(2,1)} all-gather(f16[1,8,4]{1,2,0:T(4,128)(2,1)} %bitcast.3), channel_id=3, replica_groups={{0,4},{2,6},{1,5},{3,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3316818/197889973.py\" source_line=1}, backend_config={\"flag_configs\":[],\"barrier_config\":{\"barrier_type\":\"CUSTOM\",\"id\":\"1\"},\"scoped_memory_configs\":[],\"collective_algorithm_config\":{\"emitter\":\"1DAllGatherOnMajorDim\",\"debug\":\"\\ngroup_size = 2\\nper_stride_size = 1024 bytes\\nshard_size = 1024 bytes\"}}\n",
      "  %copy.4 = f16[2,8,4]{1,0,2:T(4,128)(2,1)} copy(f16[2,8,4]{1,2,0:T(4,128)(2,1)} %all-gather.3), metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3316818/197889973.py\" source_line=1}, backend_config={\"flag_configs\":[],\"window_config\":{\"kernel_window_bounds\":[],\"output_window_bounds\":[\"4\",\"1\",\"1\"],\"input_window_bounds\":[],\"estimated_cycles\":\"286\",\"iteration_bounds\":[\"1\",\"1\",\"1\"]},\"scoped_memory_configs\":[]}\n",
      "  %reshape.4 = f16[16,4]{0,1:T(4,128)(2,1)} reshape(f16[2,8,4]{1,0,2:T(4,128)(2,1)} %copy.4), backend_config={\"flag_configs\":[],\"integer_config\":{\"integer\":\"64\"},\"scoped_memory_configs\":[]}\n",
      "  %copy.2 = f16[2,4]{0,1:T(4,128)(2,1)} copy(f16[2,4]{1,0:T(4,128)(2,1)} %param), sharding={devices=[2,4]0,2,4,6,1,3,5,7}, backend_config={\"flag_configs\":[],\"window_config\":{\"kernel_window_bounds\":[],\"output_window_bounds\":[\"1\",\"1\"],\"input_window_bounds\":[\"1\",\"1\"],\"estimated_cycles\":\"566\",\"iteration_bounds\":[\"1\",\"1\"]},\"scoped_memory_configs\":[]}\n",
      "  %bitcast.1 = f16[1,4,2]{2,1,0:T(4,128)(2,1)} bitcast(f16[2,4]{0,1:T(4,128)(2,1)} %copy.2)\n",
      "  %all-gather.2 = f16[4,4,2]{2,1,0:T(4,128)(2,1)} all-gather(f16[1,4,2]{2,1,0:T(4,128)(2,1)} %bitcast.1), channel_id=2, replica_groups={{0,2,4,6},{1,3,5,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3316818/197889973.py\" source_line=1}, backend_config={\"flag_configs\":[],\"barrier_config\":{\"barrier_type\":\"CUSTOM\",\"id\":\"0\"},\"scoped_memory_configs\":[],\"collective_algorithm_config\":{\"emitter\":\"1DAllGatherOnMajorDim\",\"debug\":\"\\ngroup_size = 4\\nper_stride_size = 1024 bytes\\nshard_size = 1024 bytes\"}}\n",
      "  %bitcast.2 = f16[16,2]{1,0:T(8,128)(2,1)} bitcast(f16[4,4,2]{2,1,0:T(4,128)(2,1)} %all-gather.2)\n",
      "  ROOT %fusion = f16[2,4]{1,0:T(4,128)(2,1)} fusion(f16[16,2]{1,0:T(8,128)(2,1)} %bitcast.2, f16[16,4]{0,1:T(4,128)(2,1)} %reshape.4), kind=kOutput, calls=%fused_computation, metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3316818/197889973.py\" source_line=1}, backend_config={\"flag_configs\":[],\"window_config\":{\"kernel_window_bounds\":[\"1\",\"1\"],\"output_window_bounds\":[\"1\",\"1\"],\"input_window_bounds\":[\"2\",\"1\"],\"estimated_cycles\":\"984\",\"iteration_bounds\":[\"1\",\"1\",\"1\"]},\"scoped_memory_configs\":[]}\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(jnp.matmul.lower(x, y).compile().as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463 µs ± 85.8 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 -r 10 jnp.matmul(x, y).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Full Sharding](https://irhum.github.io/blog/pjit/#full-sharding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "# create a vector of 1, 2, 3, 4\n",
    "v = jnp.arange(1, 5)\n",
    "# repeat the vector 16 times along the first axis\n",
    "x = jnp.repeat(v[:, None], 16, axis=1)\n",
    "\n",
    "x = jnp.asarray(x, dtype=\"f2\")\n",
    "y = jnp.copy(x).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌───────────────────────┬───────────────────────┬───────────────────────┬───────────────────────┐\n",
       "│                       │                       │                       │                       │\n",
       "│         TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>         │         TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>         │         TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>         │         TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>         │\n",
       "│                       │                       │                       │                       │\n",
       "│                       │                       │                       │                       │\n",
       "├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┤\n",
       "│                       │                       │                       │                       │\n",
       "│         TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>         │         TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>         │         TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>         │         TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>         │\n",
       "│                       │                       │                       │                       │\n",
       "│                       │                       │                       │                       │\n",
       "└───────────────────────┴───────────────────────┴───────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌───────────────────────┬───────────────────────┬───────────────────────┬───────────────────────┐\n",
       "│                       │                       │                       │                       │\n",
       "│         TPU \u001b[1;36m0\u001b[0m         │         TPU \u001b[1;36m2\u001b[0m         │         TPU \u001b[1;36m6\u001b[0m         │         TPU \u001b[1;36m4\u001b[0m         │\n",
       "│                       │                       │                       │                       │\n",
       "│                       │                       │                       │                       │\n",
       "├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┤\n",
       "│                       │                       │                       │                       │\n",
       "│         TPU \u001b[1;36m1\u001b[0m         │         TPU \u001b[1;36m3\u001b[0m         │         TPU \u001b[1;36m7\u001b[0m         │         TPU \u001b[1;36m5\u001b[0m         │\n",
       "│                       │                       │                       │                       │\n",
       "│                       │                       │                       │                       │\n",
       "└───────────────────────┴───────────────────────┴───────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = jax.device_put(x, NamedSharding(mesh, P('b', 'a')))\n",
    "jax.debug.visualize_array_sharding(x, max_width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌───────┬───────┬───────┬───────┐\n",
       "│       │       │       │       │\n",
       "│ TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> │ TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> │ TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> │ TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> │\n",
       "│       │       │       │       │\n",
       "│       │       │       │       │\n",
       "├───────┼───────┼───────┼───────┤\n",
       "│       │       │       │       │\n",
       "│ TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> │ TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> │ TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> │ TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> │\n",
       "│       │       │       │       │\n",
       "│       │       │       │       │\n",
       "└───────┴───────┴───────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌───────┬───────┬───────┬───────┐\n",
       "│       │       │       │       │\n",
       "│ TPU \u001b[1;36m0\u001b[0m │ TPU \u001b[1;36m2\u001b[0m │ TPU \u001b[1;36m6\u001b[0m │ TPU \u001b[1;36m4\u001b[0m │\n",
       "│       │       │       │       │\n",
       "│       │       │       │       │\n",
       "├───────┼───────┼───────┼───────┤\n",
       "│       │       │       │       │\n",
       "│ TPU \u001b[1;36m1\u001b[0m │ TPU \u001b[1;36m3\u001b[0m │ TPU \u001b[1;36m7\u001b[0m │ TPU \u001b[1;36m5\u001b[0m │\n",
       "│       │       │       │       │\n",
       "│       │       │       │       │\n",
       "└───────┴───────┴───────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = jax.device_put(y, NamedSharding(mesh, P('b', 'a')))\n",
    "jax.debug.visualize_array_sharding(y, max_width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌───────┬───────┬───────┬───────┐\n",
       "│       │       │       │       │\n",
       "│ TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> │ TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> │ TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> │ TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> │\n",
       "│       │       │       │       │\n",
       "│       │       │       │       │\n",
       "├───────┼───────┼───────┼───────┤\n",
       "│       │       │       │       │\n",
       "│ TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> │ TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> │ TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> │ TPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> │\n",
       "│       │       │       │       │\n",
       "│       │       │       │       │\n",
       "└───────┴───────┴───────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌───────┬───────┬───────┬───────┐\n",
       "│       │       │       │       │\n",
       "│ TPU \u001b[1;36m0\u001b[0m │ TPU \u001b[1;36m2\u001b[0m │ TPU \u001b[1;36m6\u001b[0m │ TPU \u001b[1;36m4\u001b[0m │\n",
       "│       │       │       │       │\n",
       "│       │       │       │       │\n",
       "├───────┼───────┼───────┼───────┤\n",
       "│       │       │       │       │\n",
       "│ TPU \u001b[1;36m1\u001b[0m │ TPU \u001b[1;36m3\u001b[0m │ TPU \u001b[1;36m7\u001b[0m │ TPU \u001b[1;36m5\u001b[0m │\n",
       "│       │       │       │       │\n",
       "│       │       │       │       │\n",
       "└───────┴───────┴───────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 16.  32.  48.  64.]\n",
      " [ 32.  64.  96. 128.]\n",
      " [ 48.  96. 144. 192.]\n",
      " [ 64. 128. 192. 256.]]\n"
     ]
    }
   ],
   "source": [
    "z = x@y\n",
    "jax.debug.visualize_array_sharding(z)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HloModule jit_matmul, is_scheduled=true, entry_computation_layout={(f16[2,4]{1,0:T(4,128)(2,1)}, f16[8,1]{0,1:T(4,128)(2,1)})->f16[2,1]{1,0:T(4,128)(2,1)}}, allow_spmd_sharding_propagation_to_output={true}\n",
      "\n",
      "%all-gather.3.reduce_sub_computation (lhs: f16[], rhs: f16[]) -> f16[] {\n",
      "  %lhs = f16[] parameter(0)\n",
      "  %rhs = f16[] parameter(1)\n",
      "  ROOT %add.1 = f16[] add(f16[] %lhs, f16[] %rhs)\n",
      "}\n",
      "\n",
      "%scalar_add_computation (scalar_lhs: f32[], scalar_rhs: f32[]) -> f32[] {\n",
      "  %scalar_lhs = f32[]{:T(256)} parameter(0)\n",
      "  %scalar_rhs = f32[]{:T(256)} parameter(1)\n",
      "  ROOT %add = f32[]{:T(256)} add(f32[]{:T(256)} %scalar_lhs, f32[]{:T(256)} %scalar_rhs)\n",
      "}\n",
      "\n",
      "%fused_computation (param_0.2: f16[16,2], param_1.3: f16[16]) -> f32[2] {\n",
      "  %param_0.2 = f16[16,2]{0,1:T(4,128)(2,1)} parameter(0)\n",
      "  %param_1.3 = f16[16]{0:T(512)(128)(2,1)} parameter(1)\n",
      "  %broadcast.3 = f16[16,2]{0,1:T(4,128)(2,1)} broadcast(f16[16]{0:T(512)(128)(2,1)} %param_1.3), dimensions={0}, metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3336899/197889973.py\" source_line=1}\n",
      "  %multiply.2 = f16[16,2]{0,1:T(4,128)(2,1)} multiply(f16[16,2]{0,1:T(4,128)(2,1)} %param_0.2, f16[16,2]{0,1:T(4,128)(2,1)} %broadcast.3)\n",
      "  %convert.3 = f32[16,2]{0,1:T(2,128)} convert(f16[16,2]{0,1:T(4,128)(2,1)} %multiply.2)\n",
      "  %constant.6 = f32[]{:T(256)} constant(0)\n",
      "  ROOT %reduce.3 = f32[2]{0:T(256)} reduce(f32[16,2]{0,1:T(2,128)} %convert.3, f32[]{:T(256)} %constant.6), dimensions={0}, to_apply=%scalar_add_computation\n",
      "}\n",
      "\n",
      "ENTRY %main.4_spmd (param: f16[2,4], param.1: f16[8,1]) -> f16[2,1] {\n",
      "  %constant.5 = f16[] constant(-0)\n",
      "  %param = f16[2,4]{1,0:T(4,128)(2,1)} parameter(0), sharding={devices=[2,4]0,2,4,6,1,3,5,7}\n",
      "  %param.1 = f16[8,1]{0,1:T(4,128)(2,1)} parameter(1), sharding={devices=[2,4]0,2,4,6,1,3,5,7}\n",
      "  %copy.1 = f16[2,4]{0,1:T(4,128)(2,1)} copy(f16[2,4]{1,0:T(4,128)(2,1)} %param), sharding={devices=[2,4]0,2,4,6,1,3,5,7}, backend_config={\"flag_configs\":[],\"window_config\":{\"kernel_window_bounds\":[],\"output_window_bounds\":[\"1\",\"1\"],\"input_window_bounds\":[\"1\",\"1\"],\"estimated_cycles\":\"566\",\"iteration_bounds\":[\"1\",\"1\"]},\"scoped_memory_configs\":[]}\n",
      "  %bitcast.1 = f16[1,4,2]{2,1,0:T(4,128)(2,1)} bitcast(f16[2,4]{0,1:T(4,128)(2,1)} %copy.1)\n",
      "  %all-gather.2 = f16[4,4,2]{2,1,0:T(4,128)(2,1)} all-gather(f16[1,4,2]{2,1,0:T(4,128)(2,1)} %bitcast.1), channel_id=2, replica_groups={{0,2,4,6},{1,3,5,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3336899/197889973.py\" source_line=1}, backend_config={\"flag_configs\":[],\"barrier_config\":{\"barrier_type\":\"CUSTOM\",\"id\":\"0\"},\"scoped_memory_configs\":[],\"collective_algorithm_config\":{\"emitter\":\"1DAllGatherOnMajorDim\",\"debug\":\"\\ngroup_size = 4\\nper_stride_size = 1024 bytes\\nshard_size = 1024 bytes\"}}\n",
      "  %bitcast.2 = f16[16,2]{1,0:T(8,128)(2,1)} bitcast(f16[4,4,2]{2,1,0:T(4,128)(2,1)} %all-gather.2)\n",
      "  %copy.3 = f16[16,2]{0,1:T(4,128)(2,1)} copy(f16[16,2]{1,0:T(8,128)(2,1)} %bitcast.2), backend_config={\"flag_configs\":[],\"window_config\":{\"kernel_window_bounds\":[],\"output_window_bounds\":[\"1\",\"1\"],\"input_window_bounds\":[\"2\",\"1\"],\"estimated_cycles\":\"575\",\"iteration_bounds\":[\"1\",\"1\"]},\"scoped_memory_configs\":[]}\n",
      "  %bitcast.3 = f16[1,8,1]{1,2,0:T(4,128)(2,1)} bitcast(f16[8,1]{0,1:T(4,128)(2,1)} %param.1)\n",
      "  %all-gather.3 = f16[2,8,1]{1,2,0:T(4,128)(2,1)} all-gather(f16[1,8,1]{1,2,0:T(4,128)(2,1)} %bitcast.3), channel_id=1, replica_groups={{0,1},{2,3},{4,5},{6,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3336899/197889973.py\" source_line=1}, backend_config={\"flag_configs\":[],\"barrier_config\":{\"barrier_type\":\"CUSTOM\",\"id\":\"1\"},\"scoped_memory_configs\":[],\"collective_algorithm_config\":{\"emitter\":\"1DAllGatherOnMajorDim\",\"debug\":\"\\ngroup_size = 2\\nper_stride_size = 1024 bytes\\nshard_size = 1024 bytes\"}}\n",
      "  %reduce.2 = f16[2,8]{1,0:T(4,128)(2,1)} reduce(f16[2,8,1]{1,2,0:T(4,128)(2,1)} %all-gather.3, f16[] %constant.5), dimensions={2}, to_apply=%all-gather.3.reduce_sub_computation, backend_config={\"flag_configs\":[],\"window_config\":{\"kernel_window_bounds\":[],\"output_window_bounds\":[\"2\",\"1\",\"1\"],\"input_window_bounds\":[],\"estimated_cycles\":\"249\",\"iteration_bounds\":[\"1\",\"1\",\"1\"]},\"scoped_memory_configs\":[]}\n",
      "  %reshape.4 = f16[16]{0:T(512)(128)(2,1)} reshape(f16[2,8]{1,0:T(4,128)(2,1)} %reduce.2), metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3336899/197889973.py\" source_line=1}, backend_config={\"flag_configs\":[],\"integer_config\":{\"integer\":\"16\"},\"scoped_memory_configs\":[]}\n",
      "  %fusion = f32[2]{0:T(256)} fusion(f16[16,2]{0,1:T(4,128)(2,1)} %copy.3, f16[16]{0:T(512)(128)(2,1)} %reshape.4), kind=kLoop, calls=%fused_computation, backend_config={\"flag_configs\":[],\"window_config\":{\"kernel_window_bounds\":[],\"output_window_bounds\":[\"1\",\"1\"],\"input_window_bounds\":[],\"estimated_cycles\":\"241\",\"iteration_bounds\":[\"1\",\"1\"]},\"scoped_memory_configs\":[]}\n",
      "  %convert.1 = f16[2]{0:T(512)(128)(2,1)} convert(f32[2]{0:T(256)} %fusion), metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3336899/197889973.py\" source_line=1}, backend_config={\"flag_configs\":[],\"window_config\":{\"kernel_window_bounds\":[],\"output_window_bounds\":[\"1\"],\"input_window_bounds\":[],\"estimated_cycles\":\"241\",\"iteration_bounds\":[\"1\"]},\"scoped_memory_configs\":[]}\n",
      "  ROOT %reshape.5 = f16[2,1]{1,0:T(4,128)(2,1)} reshape(f16[2]{0:T(512)(128)(2,1)} %convert.1), metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_3336899/197889973.py\" source_line=1}, backend_config={\"flag_configs\":[],\"window_config\":{\"kernel_window_bounds\":[],\"output_window_bounds\":[\"1\",\"1\"],\"input_window_bounds\":[],\"estimated_cycles\":\"248\",\"iteration_bounds\":[\"1\",\"1\"]},\"scoped_memory_configs\":[]}\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(jnp.matmul.lower(x, y).compile().as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469 µs ± 72.8 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 -r 10 jnp.matmul(x, y).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Sharding: GSPMD-style](https://irhum.github.io/blog/pjit/#sharding-gspmd-style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
